{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"KubeVirt Performance Benchmarking Suite","text":"<p>A comprehensive, vendor-neutral performance testing toolkit for KubeVirt virtual machines running on OpenShift Container Platform (OCP) or any Kubernetes distribution with KubeVirt.</p>"},{"location":"#overview","title":"Overview","text":"<p>This suite provides automated performance testing tools to measure and validate KubeVirt VM provisioning, boot times, network readiness, and failure recovery scenarios. It's designed for production environments running OpenShift Virtualization or KubeVirt with any CSI-compatible storage backend.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Unified CLI Interface: Professional kubectl-like CLI (<code>virtbench</code>) with shell completion</li> <li>VM Creation Performance Testing: Measure VM provisioning and boot times at scale</li> <li>Boot Storm Testing: Test VM startup performance when powering on multiple VMs simultaneously</li> <li>Live Migration Testing: Measure VM live migration performance across different scenarios</li> <li>Capacity Benchmark Testing: Test cluster capacity limits with comprehensive VM operations (create, resize, restart, snapshot, migrate)</li> <li>Single Node Testing: Pin all VMs to a single node for node-level capacity testing</li> <li>Failure and Recovery Testing: Validate VM recovery times after node failures</li> <li>VM Snapshot Testing: Test VM snapshot creation and readiness</li> <li>Volume Resize Testing: Test PVC expansion capabilities</li> <li>Parallel Execution: Support for testing hundreds of VMs concurrently</li> <li>Parallel Namespace Creation: Create namespaces in batches for faster test setup</li> <li>Multiple Storage Backends: Works with any CSI-compatible storage class (Portworx, Ceph, vSphere, AWS EBS, etc.)</li> <li>Comprehensive Logging: Detailed logs with timestamps and error tracking</li> <li>Flexible Configuration: Command-line arguments for easy customization</li> <li>Interactive Results Dashboard: Auto-generate rich HTML dashboards for all test results</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started in minutes:</p> <ol> <li>Install virtbench - Set up the virtbench CLI</li> <li>User Guide - Overview of testing scenarios</li> </ol>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0. See LICENSE for details.</p>"},{"location":"install/","title":"Installation Guide","text":"<p>This guide will help you install the virtbench CLI tool for running KubeVirt performance benchmarks.</p>"},{"location":"install/#prerequisites","title":"Prerequisites","text":"<p>Before installing virtbench, ensure you have the following:</p> <ul> <li>Python 3.8 or higher (required)</li> <li>pip3 (Python package manager)</li> <li>kubectl CLI configured with cluster access</li> <li>Git (to clone the repository)</li> </ul>"},{"location":"install/#installation-steps","title":"Installation Steps","text":""},{"location":"install/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/portworx/kubevirt-benchmark.git\ncd kubevirt-benchmark\n</code></pre>"},{"location":"install/#2-verify-python-version","title":"2. Verify Python Version","text":"<p>Ensure you have Python 3.8 or higher installed:</p> <pre><code>python3 --version\n</code></pre> <p>If your Python version is below 3.8, please upgrade before proceeding.</p>"},{"location":"install/#3-verify-pip-installation","title":"3. Verify pip Installation","text":"<p>Check that pip3 is installed:</p> <pre><code>pip3 --version\n</code></pre> <p>If pip3 is not installed, visit pip installation guide.</p>"},{"location":"install/#4-run-the-installation-script","title":"4. Run the Installation Script","text":"<p>The easiest way to install virtbench is using the provided installation script:</p> <pre><code>./install.sh\n</code></pre> <p>This script will: - Check Python and pip versions - Install required Python dependencies - Install the virtbench CLI tool - Verify the installation</p>"},{"location":"install/#5-installation-options","title":"5. Installation Options","text":""},{"location":"install/#standard-installation","title":"Standard Installation","text":"<p>For most users, the standard installation is recommended:</p> <pre><code>./install.sh\n</code></pre>"},{"location":"install/#virtual-environment-installation","title":"Virtual Environment Installation","text":"<p>If you're using Python 3.11+ or prefer to use a virtual environment:</p> <pre><code>./install.sh --venv\n</code></pre> <p>This creates a virtual environment in the <code>venv/</code> directory. To use virtbench after installation:</p> <pre><code>source venv/bin/activate\nvirtbench --version\n</code></pre>"},{"location":"install/#system-wide-installation-advanced","title":"System-Wide Installation (Advanced)","text":"<p>To force system-wide installation (not recommended for Python 3.11+):</p> <pre><code>./install.sh --system\n</code></pre>"},{"location":"install/#6-verify-installation","title":"6. Verify Installation","text":"<p>After installation, verify that virtbench is available:</p> <pre><code>virtbench --version\n</code></pre> <p>You should see output similar to:</p> <pre><code>virtbench version 1.0.0\n</code></pre>"},{"location":"install/#7-enable-shell-completion-optional","title":"7. Enable Shell Completion (Optional)","text":"<p>Enable tab completion for virtbench commands:</p> <p>For Bash:</p> <pre><code>echo 'eval \"$(_VIRTBENCH_COMPLETE=bash_source virtbench)\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>For Zsh:</p> <pre><code>echo 'eval \"$(_VIRTBENCH_COMPLETE=zsh_source virtbench)\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"install/#8-verify-kubectl-access","title":"8. Verify kubectl Access","text":"<p>Ensure kubectl is configured and you have access to your cluster:</p> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"install/#9-validate-cluster-prerequisites","title":"9. Validate Cluster Prerequisites","text":"<p>Run the cluster validation command to ensure your cluster is ready:</p> <pre><code>virtbench validate-cluster --storage-class YOUR-STORAGE-CLASS\n</code></pre> <p>Replace <code>YOUR-STORAGE-CLASS</code> with the name of your storage class.</p>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"install/#virtbench-command-not-found","title":"virtbench command not found","text":"<p>If the <code>virtbench</code> command is not found after installation, you may need to add <code>~/.local/bin</code> to your PATH:</p> <pre><code>export PATH=\"$HOME/.local/bin:$PATH\"\n</code></pre> <p>Add this line to your <code>~/.bashrc</code> or <code>~/.zshrc</code> to make it permanent.</p>"},{"location":"install/#python-version-too-old","title":"Python version too old","text":"<p>If you see an error about Python version, upgrade Python to 3.8 or higher:</p> <p>On RHEL/CentOS:</p> <pre><code>sudo yum install python3.8\n</code></pre> <p>On Ubuntu/Debian:</p> <pre><code>sudo apt-get install python3.8\n</code></pre> <p>On macOS:</p> <pre><code>brew install python@3.8\n</code></pre>"},{"location":"install/#permission-denied-errors","title":"Permission denied errors","text":"<p>If you encounter permission errors during installation, try:</p> <pre><code>./install.sh --venv\n</code></pre> <p>This installs virtbench in a virtual environment without requiring system-level permissions.</p>"},{"location":"install/#next-steps","title":"Next Steps","text":"<p>Now that virtbench is installed, you can:</p> <ol> <li>Review User Guide - Understand testing scenarios</li> <li>Validate Your Cluster - Run pre-flight checks</li> <li>Run Your First Test - Start benchmarking</li> </ol>"},{"location":"install/#uninstallation","title":"Uninstallation","text":"<p>To uninstall virtbench:</p> <pre><code>pip3 uninstall virtbench\n</code></pre> <p>If you used a virtual environment, simply delete the <code>venv/</code> directory:</p> <pre><code>rm -rf venv/\n</code></pre>"},{"location":"license/","title":"License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>Copyright 2025 Pure Storage</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"community/","title":"Community","text":"<p>Welcome to the virtbench community! This project is the work of many contributors, and we welcome your participation.</p>"},{"location":"community/#get-involved","title":"Get Involved","text":"<ul> <li>Contributing - Learn how to contribute to the project</li> <li>Support - Get help and support</li> <li>Code of Conduct - Community guidelines</li> </ul>"},{"location":"community/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Report bugs and request features via GitHub Issues</li> <li>Submit pull requests with improvements</li> <li>Improve documentation</li> <li>Share your benchmarking results and use cases</li> <li>Help answer questions from other users</li> </ul>"},{"location":"community/#communication","title":"Communication","text":"<ul> <li>GitHub Issues: Search existing issues or open a new one</li> <li>Discussions: Share ideas and ask questions</li> <li>Pull Requests: Contribute code and documentation improvements</li> </ul> <p>We're excited to have you as part of the community!</p>"},{"location":"community/support/","title":"Support","text":"<p>Use the GitHub issues to report bugs or suggest features and enhancements. Issues are monitored and prioritized by the maintainers.</p> <p>Please include as much detail as possible. Information like the following is extremely helpful in allowing us to accurately evaluate and prioritize potential changes:</p> <ul> <li>A reproducible test case or clear sequence of steps</li> <li>Any modifications you\u2019ve made that may be relevant to the issue</li> <li>Anything unusual or unique about your environment or deployment setup</li> </ul>"},{"location":"reference/best-practices/","title":"Best Practices","text":"<p>This guide provides recommendations for running effective and reliable performance tests with virtbench.</p>"},{"location":"reference/best-practices/#general-testing-practices","title":"General Testing Practices","text":""},{"location":"reference/best-practices/#1-start-small-scale-gradually","title":"1. Start Small, Scale Gradually","text":"<ul> <li>Begin with 5-10 VMs to validate your setup</li> <li>Gradually increase to 50, 100, 200+ VMs</li> <li>Identify bottlenecks at each scale</li> <li>Understand your infrastructure limits before large-scale tests</li> </ul>"},{"location":"reference/best-practices/#2-run-multiple-tests","title":"2. Run Multiple Tests","text":"<ul> <li>Run each test at least 3 times for consistency</li> <li>Average results across multiple runs</li> <li>Identify and investigate outliers</li> <li>Account for cluster variability</li> </ul>"},{"location":"reference/best-practices/#3-save-results-consistently","title":"3. Save Results Consistently","text":"<p>Always use <code>--save-results</code> to track performance over time:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --save-results \\\n  --storage-version 3.2.0\n</code></pre>"},{"location":"reference/best-practices/#4-use-meaningful-test-names","title":"4. Use Meaningful Test Names","text":"<p>Organize results with storage version and configuration details:</p> <pre><code>--storage-version \"portworx-3.2.0\"\n--storage-version \"ceph-rbd-17.2\"\n</code></pre>"},{"location":"reference/best-practices/#5-monitor-cluster-resources","title":"5. Monitor Cluster Resources","text":"<p>Watch cluster resources during tests:</p> <pre><code># In a separate terminal\nwatch kubectl top nodes\n\n# Check storage backend metrics\n# (specific to your storage solution)\n</code></pre>"},{"location":"reference/best-practices/#vm-creation-testing","title":"VM Creation Testing","text":""},{"location":"reference/best-practices/#1-validate-cluster-first","title":"1. Validate Cluster First","text":"<p>Always run cluster validation before testing:</p> <pre><code>virtbench validate-cluster --storage-class YOUR-STORAGE-CLASS\n</code></pre>"},{"location":"reference/best-practices/#2-use-appropriate-concurrency","title":"2. Use Appropriate Concurrency","text":"<ul> <li>Default concurrency (50) works for most scenarios</li> <li>Increase for large-scale tests (100-200 VMs)</li> <li>Decrease if experiencing resource contention</li> </ul> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 200 \\\n  --concurrency 200 \\\n  --storage-class YOUR-STORAGE-CLASS\n</code></pre>"},{"location":"reference/best-practices/#3-namespace-batch-creation","title":"3. Namespace Batch Creation","text":"<p>Create namespaces in batches for faster setup:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --namespace-batch-size 50 \\\n  --storage-class YOUR-STORAGE-CLASS\n</code></pre>"},{"location":"reference/best-practices/#4-boot-storm-testing","title":"4. Boot Storm Testing","text":"<ul> <li>Test both single-node and multi-node boot storms</li> <li>Start with smaller VM counts (20-30)</li> <li>Gradually increase to find capacity limits</li> <li>Compare initial creation vs boot storm performance</li> </ul>"},{"location":"reference/best-practices/#migration-testing","title":"Migration Testing","text":""},{"location":"reference/best-practices/#1-verify-vms-before-migration","title":"1. Verify VMs Before Migration","text":"<p>Ensure VMs are healthy before starting migration tests:</p> <pre><code># Check VM status\nkubectl get vm -n kubevirt-perf-test-1\n\n# Verify network connectivity\nkubectl exec -it ssh-test-pod -- ping &lt;vm-ip&gt;\n</code></pre>"},{"location":"reference/best-practices/#2-choose-appropriate-migration-scenario","title":"2. Choose Appropriate Migration Scenario","text":"<ul> <li>Sequential: For baseline performance</li> <li>Parallel: For stress testing</li> <li>Evacuation: For node maintenance scenarios</li> <li>Round-robin: For load balancing validation</li> </ul>"},{"location":"reference/best-practices/#3-set-realistic-timeouts","title":"3. Set Realistic Timeouts","text":"<p>Adjust timeouts based on VM size and network:</p> <pre><code>virtbench migration \\\n  --start 1 \\\n  --end 10 \\\n  --migration-timeout 600 \\  # 10 minutes for large VMs\n  --source-node worker-1\n</code></pre>"},{"location":"reference/best-practices/#capacity-benchmark-testing","title":"Capacity Benchmark Testing","text":""},{"location":"reference/best-practices/#1-understand-your-goals","title":"1. Understand Your Goals","text":"<ul> <li>Find Maximum Capacity: Run without <code>--max-iterations</code></li> <li>Test Specific Scenarios: Use <code>--max-iterations</code> to limit test duration</li> <li>Skip Unsupported Features: Use <code>--skip-resize-job</code> or <code>--skip-snapshot-job</code> if needed</li> </ul>"},{"location":"reference/best-practices/#2-start-with-conservative-settings","title":"2. Start with Conservative Settings","text":"<pre><code>virtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --max-iterations 5\n</code></pre>"},{"location":"reference/best-practices/#3-monitor-for-failures","title":"3. Monitor for Failures","text":"<ul> <li>Watch for resource exhaustion</li> <li>Check storage backend health</li> <li>Monitor node resources</li> <li>Review logs for errors</li> </ul>"},{"location":"reference/best-practices/#failure-recovery-testing","title":"Failure Recovery Testing","text":""},{"location":"reference/best-practices/#1-test-in-non-production-first","title":"1. Test in Non-Production First","text":"<ul> <li>Validate FAR configuration in test environment</li> <li>Understand recovery behavior before production use</li> <li>Document expected recovery times</li> </ul>"},{"location":"reference/best-practices/#2-use-appropriate-timeouts","title":"2. Use Appropriate Timeouts","text":"<p>Set timeouts based on your RTO requirements:</p> <pre><code>virtbench failure-recovery \\\n  --start 1 \\\n  --end 10 \\\n  --recovery-timeout 600  # 10 minutes\n</code></pre>"},{"location":"reference/best-practices/#3-clean-up-far-resources","title":"3. Clean Up FAR Resources","text":"<p>Always clean up FAR resources after testing:</p> <pre><code>virtbench failure-recovery \\\n  --start 1 \\\n  --end 10 \\\n  --cleanup \\\n  --cleanup-vms\n</code></pre>"},{"location":"reference/best-practices/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"reference/best-practices/#1-use-appropriate-log-levels","title":"1. Use Appropriate Log Levels","text":"<ul> <li>INFO: Normal operation (default)</li> <li>DEBUG: Detailed troubleshooting</li> <li>WARNING: Important issues only</li> <li>ERROR: Critical errors only</li> </ul>"},{"location":"reference/best-practices/#2-save-logs-to-files","title":"2. Save Logs to Files","text":"<pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --log-file test-$(date +%Y%m%d-%H%M%S).log\n</code></pre>"},{"location":"reference/best-practices/#3-review-logs-after-tests","title":"3. Review Logs After Tests","text":"<ul> <li>Check for errors and warnings</li> <li>Identify performance bottlenecks</li> <li>Validate test completion</li> </ul>"},{"location":"reference/best-practices/#cleanup-practices","title":"Cleanup Practices","text":""},{"location":"reference/best-practices/#1-always-clean-up-after-tests","title":"1. Always Clean Up After Tests","text":"<pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --cleanup\n</code></pre>"},{"location":"reference/best-practices/#2-use-dry-run-first","title":"2. Use Dry Run First","text":"<p>Preview cleanup before executing:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --dry-run-cleanup\n</code></pre>"},{"location":"reference/best-practices/#3-clean-up-on-failure","title":"3. Clean Up on Failure","text":"<p>Ensure resources are cleaned up even if tests fail:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --cleanup-on-failure\n</code></pre>"},{"location":"reference/best-practices/#results-management","title":"Results Management","text":""},{"location":"reference/best-practices/#1-organize-results-by-version","title":"1. Organize Results by Version","text":"<p>Use <code>--storage-version</code> to organize results:</p> <pre><code>--storage-version \"portworx-3.2.0\"\n</code></pre>"},{"location":"reference/best-practices/#2-generate-dashboards-regularly","title":"2. Generate Dashboards Regularly","text":"<p>Create dashboards after each test run:</p> <pre><code>python3 dashboard/generate_dashboard.py --days 30\n</code></pre>"},{"location":"reference/best-practices/#3-archive-important-results","title":"3. Archive Important Results","text":"<ul> <li>Save dashboard HTML files</li> <li>Keep JSON/CSV results for historical comparison</li> <li>Document test conditions and configurations</li> </ul>"},{"location":"reference/best-practices/#performance-optimization","title":"Performance Optimization","text":""},{"location":"reference/best-practices/#1-tune-for-your-environment","title":"1. Tune for Your Environment","text":"<ul> <li>Adjust concurrency based on cluster size</li> <li>Optimize namespace batch size</li> <li>Configure appropriate timeouts</li> </ul>"},{"location":"reference/best-practices/#2-minimize-external-load","title":"2. Minimize External Load","text":"<ul> <li>Run tests when cluster is not under load</li> <li>Avoid running multiple tests simultaneously</li> <li>Ensure storage backend is not saturated</li> </ul>"},{"location":"reference/best-practices/#3-use-consistent-test-conditions","title":"3. Use Consistent Test Conditions","text":"<ul> <li>Same time of day</li> <li>Same cluster state</li> <li>Same resource availability</li> </ul>"},{"location":"reference/best-practices/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - All available options</li> <li>Troubleshooting - Common issues and solutions</li> <li>Output and Results - Understanding test output</li> <li>Cleanup Guide - Cleanup procedures</li> </ul>"},{"location":"reference/troubleshooting/","title":"Troubleshooting","text":"<p>This guide helps you diagnose and resolve common issues when running virtbench performance tests.</p>"},{"location":"reference/troubleshooting/#general-issues","title":"General Issues","text":""},{"location":"reference/troubleshooting/#python-version-too-old","title":"Python Version Too Old","text":"<p>Symptoms: Script exits with \"Python 3.8+ is required\"</p> <p>Solutions: - Upgrade Python to 3.8 or higher - On RHEL/CentOS: <code>sudo yum install python3.8</code> - On Ubuntu/Debian: <code>sudo apt-get install python3.8</code> - On macOS: <code>brew install python@3.8</code></p>"},{"location":"reference/troubleshooting/#kubectl-not-found-or-not-configured","title":"kubectl Not Found or Not Configured","text":"<p>Symptoms: \"kubectl: command not found\" or \"The connection to the server was refused\"</p> <p>Solutions: - Install kubectl: Follow Kubernetes documentation - Configure kubectl: <code>export KUBECONFIG=/path/to/kubeconfig</code> - Test connection: <code>kubectl get nodes</code></p>"},{"location":"reference/troubleshooting/#virtbench-command-not-found","title":"virtbench Command Not Found","text":"<p>Symptoms: \"virtbench: command not found\" after installation</p> <p>Solutions: - Add <code>~/.local/bin</code> to PATH: <code>export PATH=\"$HOME/.local/bin:$PATH\"</code> - Make it permanent: Add to <code>~/.bashrc</code> or <code>~/.zshrc</code> - If using venv: Activate it first: <code>source venv/bin/activate</code> - Reinstall: <code>pip3 install -e .</code></p>"},{"location":"reference/troubleshooting/#vm-creation-issues","title":"VM Creation Issues","text":""},{"location":"reference/troubleshooting/#datasource-not-found","title":"DataSource Not Found","text":"<p>Symptoms: VM creation fails with \"DataSource 'rhel9' not found\"</p> <p>Solutions: - List available DataSources: <code>kubectl get datasource -n openshift-virtualization-os-images</code> - Check DataSource name in template matches available DataSources - Verify OpenShift Virtualization is properly installed - Wait for DataSources to be created (may take a few minutes after installation)</p>"},{"location":"reference/troubleshooting/#storage-class-not-found","title":"Storage Class Not Found","text":"<p>Symptoms: PVC creation fails with \"StorageClass not found\"</p> <p>Solutions: - List available storage classes: <code>kubectl get storageclass</code> - Verify storage class name is correct - Ensure storage class is properly configured - Check if storage backend is healthy</p>"},{"location":"reference/troubleshooting/#vms-stuck-in-provisioning","title":"VMs Stuck in Provisioning","text":"<p>Symptoms: VMs remain in \"Provisioning\" state for extended time</p> <p>Solutions: - Check DataVolume status: <code>kubectl get dv -n &lt;namespace&gt;</code> - Check CDI logs: <code>kubectl logs -n openshift-cnv -l app=cdi-deployment</code> - Verify storage backend is healthy - Check for resource constraints on nodes - Increase timeout values if storage is slow</p>"},{"location":"reference/troubleshooting/#vms-not-reaching-running-state","title":"VMs Not Reaching Running State","text":"<p>Symptoms: VMs stuck in \"Starting\" or other non-Running states</p> <p>Solutions: - Check VM events: <code>kubectl describe vm &lt;vm-name&gt; -n &lt;namespace&gt;</code> - Check VMI status: <code>kubectl get vmi &lt;vm-name&gt; -n &lt;namespace&gt;</code> - Check virt-launcher pod logs: <code>kubectl logs virt-launcher-&lt;vm-name&gt;-xxx -n &lt;namespace&gt;</code> - Verify node has sufficient resources - Check VM console for boot errors: <code>virtctl console &lt;vm-name&gt; -n &lt;namespace&gt;</code></p>"},{"location":"reference/troubleshooting/#permission-denied-errors","title":"Permission Denied Errors","text":"<p>Symptoms: Cannot create namespaces, VMs, or other resources</p> <p>Solutions: - Ensure your user has cluster-admin or equivalent permissions - Check RBAC policies: <code>kubectl auth can-i create vm --all-namespaces</code> - Verify service account permissions if running in a pod</p>"},{"location":"reference/troubleshooting/#golden-image-pvcs-not-ready","title":"Golden Image PVCs Not Ready","text":"<p>Symptoms: DataSource or DataVolume not found</p> <p>Solutions: - Check DataVolume status: <code>kubectl get dv -n openshift-virtualization-os-images</code> - Verify registry image stream exists: <code>kubectl get imagestream -n openshift-virtualization-os-images</code> - Check CDI operator logs: <code>kubectl logs -n openshift-cnv -l name=cdi-operator</code></p>"},{"location":"reference/troubleshooting/#capacity-benchmark-issues","title":"Capacity Benchmark Issues","text":""},{"location":"reference/troubleshooting/#volume-resize-fails","title":"Volume Resize Fails","text":"<p>Symptoms: Resize phase fails with error</p> <p>Solutions: - Check if your storage class supports volume expansion:   <code>bash   kubectl get storageclass YOUR-STORAGE-CLASS -o jsonpath='{.allowVolumeExpansion}'</code> - If <code>false</code>, use <code>--skip-resize-job</code> to skip this phase - Check storage backend limits and quotas</p>"},{"location":"reference/troubleshooting/#snapshot-creation-fails","title":"Snapshot Creation Fails","text":"<p>Symptoms: Snapshot phase fails</p> <p>Solutions: - Check if VolumeSnapshotClass is configured:   <code>bash   kubectl get volumesnapshotclass</code> - If not available, use <code>--skip-snapshot-job</code> to skip this phase - Verify storage backend supports CSI snapshots</p>"},{"location":"reference/troubleshooting/#out-of-resources-vm-creation-fails","title":"Out of Resources (VM Creation Fails)","text":"<p>Symptoms: VMs stuck in Scheduling state, capacity limit reached</p> <p>Solutions: - This indicates you've reached capacity limits. Check:   ```bash   # Check node resources   kubectl top nodes</p> <p># Check node status   kubectl describe node node-name   ``` - Review cluster resource quotas - Add more worker nodes or increase node resources</p>"},{"location":"reference/troubleshooting/#migration-issues","title":"Migration Issues","text":""},{"location":"reference/troubleshooting/#migration-stuck-or-timeout","title":"Migration Stuck or Timeout","text":"<p>Symptoms: Migration doesn't complete within timeout</p> <p>Solutions: - Increase <code>--migration-timeout</code> value - Check network bandwidth between nodes - Verify storage backend supports live migration - Check virt-handler logs on source and target nodes</p>"},{"location":"reference/troubleshooting/#migration-fails-immediately","title":"Migration Fails Immediately","text":"<p>Symptoms: Migration fails right after starting</p> <p>Solutions: - Verify VM is in Running state before migration - Check if VM has any conditions preventing migration - Review VMIM resource for error details: <code>kubectl describe vmim -n &lt;namespace&gt;</code></p>"},{"location":"reference/troubleshooting/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code># Using virtbench CLI\nvirtbench datasource-clone --log-level DEBUG --start 1 --end 5\n\n# Using Python script\npython3 measure-vm-creation-time.py --log-level DEBUG --start 1 --end 5\n</code></pre>"},{"location":"reference/troubleshooting/#performance-baselines","title":"Performance Baselines","text":""},{"location":"reference/troubleshooting/#expected-performance-ranges","title":"Expected Performance Ranges","text":"<p>These are general guidelines. Actual performance depends on your infrastructure:</p>"},{"location":"reference/troubleshooting/#vm-creation-datasource-clone","title":"VM Creation (DataSource Clone)","text":"Storage Type Time to Running Time to Ping Local SSD 10-20s 30-45s Network SSD (Portworx, Ceph) 15-30s 40-60s Network HDD 30-60s 60-120s"},{"location":"reference/troubleshooting/#live-migration","title":"Live Migration","text":"VM Size Migration Duration Small (2GB RAM) 10-30s Medium (4-8GB RAM) 30-60s Large (16GB+ RAM) 60-180s"},{"location":"reference/troubleshooting/#boot-storm-impact","title":"Boot Storm Impact","text":"<p>Expect 1.5-3x slower performance during boot storm compared to sequential creation.</p>"},{"location":"reference/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still experiencing issues:</p> <ol> <li>Check Logs: Review test logs with <code>--log-level DEBUG</code></li> <li>Search Issues: Search existing GitHub issues</li> <li>Open an Issue: Create a new issue with:</li> <li>virtbench version</li> <li>Cluster details (OCP version, KubeVirt version)</li> <li>Storage backend</li> <li>Full error messages and logs</li> <li>Steps to reproduce</li> </ol>"},{"location":"reference/troubleshooting/#see-also","title":"See Also","text":"<ul> <li>Cluster Validation - Pre-flight checks</li> <li>Configuration Options - All available options</li> <li>Best Practices - Recommended practices</li> </ul>"},{"location":"reference/user-guide/boot-storm-guide/","title":"Boot Storm Testing Guide","text":"<p>A \"boot storm\" occurs when many VMs start simultaneously, creating high demand on storage I/O, network resources, compute resources, and hypervisor scheduling. This guide explains how to test and understand boot storm performance.</p>"},{"location":"reference/user-guide/boot-storm-guide/#what-is-boot-storm-testing","title":"What is Boot Storm Testing?","text":"<p>Boot storm testing helps you understand:</p> <ol> <li>Concurrent Startup Performance: How your infrastructure handles simultaneous VM startups</li> <li>Performance Degradation: Impact of load on individual VM boot times</li> <li>Bottleneck Identification: Discover limits in storage, network, or compute</li> <li>Recovery Time Objectives (RTO): Realistic expectations for disaster recovery scenarios</li> </ol>"},{"location":"reference/user-guide/boot-storm-guide/#boot-storm-test-workflow","title":"Boot Storm Test Workflow","text":"<p>The boot storm test follows a four-phase workflow:</p>"},{"location":"reference/user-guide/boot-storm-guide/#phase-1-initial-vm-creation","title":"Phase 1: Initial VM Creation","text":"<ol> <li>Creates all test namespaces in parallel batches</li> <li>Creates and starts all VMs simultaneously</li> <li>Measures time to Running state for each VM</li> <li>Measures time to network readiness (ping) for each VM</li> <li>Displays initial creation performance results</li> </ol> <p>This phase establishes a baseline for comparison.</p>"},{"location":"reference/user-guide/boot-storm-guide/#phase-2-shutdown-all-vms","title":"Phase 2: Shutdown All VMs","text":"<ol> <li>Issues stop commands to all VMs in parallel</li> <li>Waits for all VMIs to be deleted (VMs fully stopped)</li> <li>Confirms all VMs are in stopped state</li> </ol> <p>This ensures a clean starting point for the boot storm test.</p>"},{"location":"reference/user-guide/boot-storm-guide/#phase-3-boot-storm-simultaneous-startup","title":"Phase 3: Boot Storm (Simultaneous Startup)","text":"<ol> <li>Issues start commands to ALL VMs at once</li> <li>Creates maximum load on infrastructure</li> <li>Measures time to Running state for each VM</li> <li>Measures time to network readiness for each VM</li> <li>Displays boot storm performance results</li> </ol> <p>This is the actual boot storm test.</p>"},{"location":"reference/user-guide/boot-storm-guide/#phase-4-comparison","title":"Phase 4: Comparison","text":"<p>Compare initial creation vs boot storm metrics to understand: - Performance differences between cold start and warm start - Impact of concurrent operations - Storage backend behavior under load - Infrastructure capacity limits</p>"},{"location":"reference/user-guide/boot-storm-guide/#testing-scenarios","title":"Testing Scenarios","text":""},{"location":"reference/user-guide/boot-storm-guide/#single-node-boot-storm","title":"Single Node Boot Storm","text":"<p>Tests VM startup performance on a single node when powering on multiple VMs simultaneously.</p> <p>Use Case: Validates node-level capacity and boot storm performance (e.g., how many VMs can a single node handle during boot storm).</p> <p>Command:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --single-node \\\n  --boot-storm \\\n  --save-results\n</code></pre> <p>What it does: 1. Selects a single node (random or specified with <code>--node-name</code>) 2. Creates and starts all VMs on that node (initial test) 3. Stops all VMs and waits for complete shutdown 4. Starts all VMs simultaneously on the same node (boot storm) 5. Measures time to Running state and time to ping for each VM 6. Provides separate statistics for initial creation and boot storm</p>"},{"location":"reference/user-guide/boot-storm-guide/#multi-node-boot-storm","title":"Multi-Node Boot Storm","text":"<p>Tests VM startup performance across all nodes when powering on multiple VMs simultaneously.</p> <p>Use Case: Validates cluster-wide performance under boot storm conditions (e.g., after maintenance, power outage recovery).</p> <p>Command:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --boot-storm \\\n  --save-results\n</code></pre> <p>What it does: 1. Creates and starts all VMs (distributed across nodes) 2. Stops all VMs and waits for complete shutdown 3. Starts all VMs simultaneously (boot storm) 4. Measures time to Running state and time to ping for each VM 5. Provides separate statistics for initial creation and boot storm</p>"},{"location":"reference/user-guide/boot-storm-guide/#interpreting-boot-storm-results","title":"Interpreting Boot Storm Results","text":""},{"location":"reference/user-guide/boot-storm-guide/#key-metrics","title":"Key Metrics","text":"<ul> <li>Time to Running: How long until VM reaches Running state</li> <li>Time to Ping: How long until VM is network-reachable</li> <li>Average Times: Mean performance across all VMs</li> <li>Max Times: Worst-case performance (important for SLA planning)</li> <li>Success Rate: Percentage of VMs that successfully started</li> </ul>"},{"location":"reference/user-guide/boot-storm-guide/#what-to-look-for","title":"What to Look For","text":"<p>Good Performance Indicators: - Boot storm times similar to initial creation times - Consistent performance across all VMs - High success rate (100%) - Predictable max times</p> <p>Performance Issues: - Boot storm times significantly higher than initial creation - Wide variance in boot times - VMs failing to start - Increasing times as more VMs start</p>"},{"location":"reference/user-guide/boot-storm-guide/#common-bottlenecks","title":"Common Bottlenecks","text":"<ol> <li>Storage I/O: High disk read/write contention</li> <li>Network: Bandwidth saturation during image pulls</li> <li>Compute: CPU/memory exhaustion on nodes</li> <li>Hypervisor: KubeVirt scheduling delays</li> </ol>"},{"location":"reference/user-guide/boot-storm-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Start Small: Begin with 10-20 VMs to establish baseline</li> <li>Incremental Testing: Gradually increase VM count to find limits</li> <li>Monitor Resources: Watch node CPU, memory, and storage I/O during tests</li> <li>Multiple Runs: Run tests multiple times for consistent results</li> <li>Save Results: Always use <code>--save-results</code> to track performance over time</li> <li>Clean Environment: Ensure cluster is not under load before testing</li> </ol>"},{"location":"reference/user-guide/boot-storm-guide/#advanced-options","title":"Advanced Options","text":""},{"location":"reference/user-guide/boot-storm-guide/#namespace-batch-size","title":"Namespace Batch Size","text":"<p>Control how many namespaces are created in parallel:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --boot-storm \\\n  --namespace-batch-size 50\n</code></pre>"},{"location":"reference/user-guide/boot-storm-guide/#concurrency-control","title":"Concurrency Control","text":"<p>Adjust monitoring concurrency for large-scale tests:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 200 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --boot-storm \\\n  --concurrency 200\n</code></pre>"},{"location":"reference/user-guide/boot-storm-guide/#see-also","title":"See Also","text":"<ul> <li>DataSource Clone Testing - Full VM creation guide</li> <li>Configuration Options - All available options</li> <li>Output and Results - Understanding test output</li> </ul>"},{"location":"reference/user-guide/cleanup-guide/","title":"Cleanup Guide","text":"<p>All test scripts support comprehensive cleanup with multiple options for different scenarios.</p>"},{"location":"reference/user-guide/cleanup-guide/#cleanup-options","title":"Cleanup Options","text":"Option Description <code>--cleanup</code> Delete resources and namespaces after test completes <code>--cleanup-on-failure</code> Clean up resources even if tests fail <code>--dry-run-cleanup</code> Show what would be deleted without actually deleting <code>--yes</code> Skip confirmation prompt for cleanup"},{"location":"reference/user-guide/cleanup-guide/#what-gets-cleaned-up","title":"What Gets Cleaned Up","text":""},{"location":"reference/user-guide/cleanup-guide/#vm-creation-tests","title":"VM Creation Tests","text":"<ul> <li>All VMs created during the test</li> <li>All DataVolumes (DVs) associated with the VMs</li> <li>All PersistentVolumeClaims (PVCs)</li> <li>All test namespaces (kubevirt-perf-test-1 through kubevirt-perf-test-N)</li> </ul>"},{"location":"reference/user-guide/cleanup-guide/#migration-tests","title":"Migration Tests","text":"<ul> <li>VirtualMachineInstanceMigration (VMIM) resources</li> <li>Optionally: VMs, DataVolumes, PVCs, and namespaces (if <code>--create-vms</code> was used)</li> </ul>"},{"location":"reference/user-guide/cleanup-guide/#failure-recovery-tests","title":"Failure Recovery Tests","text":"<ul> <li>FenceAgentsRemediation (FAR) custom resources</li> <li>FAR annotations from VMs</li> <li>Uncordon nodes that were marked as failed</li> <li>Optionally: VMs, DataVolumes, PVCs, and namespaces (with <code>--cleanup-vms</code>)</li> </ul>"},{"location":"reference/user-guide/cleanup-guide/#capacity-benchmark-tests","title":"Capacity Benchmark Tests","text":"<ul> <li>All VMs in the test namespace</li> <li>All DataVolumes and PVCs</li> <li>All VolumeSnapshots</li> <li>The entire test namespace</li> </ul>"},{"location":"reference/user-guide/cleanup-guide/#cleanup-examples","title":"Cleanup Examples","text":""},{"location":"reference/user-guide/cleanup-guide/#clean-up-after-vm-creation-tests","title":"Clean up after VM Creation Tests","text":"<p>virtbench CLI:</p> <pre><code># Clean up after test\nvirtbench datasource-clone --start 1 --end 50 --storage-class YOUR-STORAGE-CLASS --cleanup\n\n# Dry run to see what would be deleted\nvirtbench datasource-clone --start 1 --end 50 --storage-class YOUR-STORAGE-CLASS --dry-run-cleanup\n\n# Clean up even if tests fail\nvirtbench datasource-clone --start 1 --end 50 --storage-class YOUR-STORAGE-CLASS --cleanup-on-failure\n</code></pre> <p>Python Script:</p> <pre><code>cd datasource-clone\n\n# Clean up after test\npython3 measure-vm-creation-time.py --start 1 --end 50 --cleanup\n\n# Dry run to see what would be deleted\npython3 measure-vm-creation-time.py --start 1 --end 50 --dry-run-cleanup\n\n# Clean up even if tests fail\npython3 measure-vm-creation-time.py --start 1 --end 50 --cleanup-on-failure\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#clean-up-after-migration-tests","title":"Clean up after Migration Tests","text":"<p>virtbench CLI:</p> <pre><code># Clean up VMIMs only (VMs were pre-existing)\nvirtbench migration --start 1 --end 10 --source-node worker-1 --cleanup\n\n# Clean up everything (VMs were created by test)\nvirtbench migration --start 1 --end 10 --source-node worker-1 --create-vms --cleanup\n</code></pre> <p>Python Script:</p> <pre><code>cd migration\n\n# Clean up VMIMs only\npython3 measure-vm-migration-time.py --start 1 --end 10 --source-node worker-1 --cleanup\n\n# Clean up everything\npython3 measure-vm-migration-time.py --start 1 --end 10 --source-node worker-1 --create-vms --cleanup\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#clean-up-after-failure-recovery-tests","title":"Clean up after Failure Recovery Tests","text":"<p>virtbench CLI:</p> <pre><code># Clean up FAR resources only\nvirtbench failure-recovery --start 1 --end 10 --cleanup\n\n# Clean up FAR resources and VMs\nvirtbench failure-recovery --start 1 --end 10 --cleanup --cleanup-vms\n</code></pre> <p>Python Script:</p> <pre><code>cd failure-recovery\n\n# Clean up FAR resources only\npython3 measure-recovery-time.py --start 1 --end 10 --cleanup\n\n# Clean up FAR resources and VMs\npython3 measure-recovery-time.py --start 1 --end 10 --cleanup --cleanup-vms\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#clean-up-after-capacity-benchmark","title":"Clean up after Capacity Benchmark","text":"<p>virtbench CLI:</p> <pre><code># Clean up after test\nvirtbench capacity-benchmark --storage-class YOUR-STORAGE-CLASS --cleanup\n\n# Cleanup only (from previous run)\nvirtbench capacity-benchmark --cleanup-only\n</code></pre> <p>Python Script:</p> <pre><code>cd capacity-benchmark\n\n# Clean up after test\npython3 measure-capacity.py --storage-class YOUR-STORAGE-CLASS --cleanup\n\n# Cleanup only (from previous run)\npython3 measure-capacity.py --cleanup-only\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#manual-cleanup","title":"Manual Cleanup","text":"<p>If automated cleanup fails or you need to clean up manually:</p>"},{"location":"reference/user-guide/cleanup-guide/#delete-test-namespaces","title":"Delete Test Namespaces","text":"<pre><code># Delete all test namespaces\nkubectl delete namespace -l app=kubevirt-perf-test\n\n# Delete specific range\nfor i in {1..50}; do\n  kubectl delete namespace kubevirt-perf-test-$i --ignore-not-found=true\ndone\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#delete-specific-resources","title":"Delete Specific Resources","text":"<pre><code># Delete VMs in a namespace\nkubectl delete vm --all -n kubevirt-perf-test-1\n\n# Delete DataVolumes\nkubectl delete dv --all -n kubevirt-perf-test-1\n\n# Delete PVCs\nkubectl delete pvc --all -n kubevirt-perf-test-1\n\n# Delete VMIMs\nkubectl delete vmim --all -n kubevirt-perf-test-1\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#delete-far-resources","title":"Delete FAR Resources","text":"<pre><code># Delete FAR custom resource\nkubectl delete fenceagentsremediation &lt;far-name&gt; -n &lt;namespace&gt;\n\n# Remove FAR annotations from VMs\nkubectl annotate vm &lt;vm-name&gt; fence.agents.remediation.medik8s.io/fence-agent- -n &lt;namespace&gt;\n\n# Uncordon nodes\nkubectl uncordon &lt;node-name&gt;\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Use Dry Run First: Always use <code>--dry-run-cleanup</code> to preview what will be deleted</li> <li>Confirm Deletions: Review the confirmation prompt carefully before proceeding</li> <li>Save Results First: Ensure results are saved before cleanup if needed</li> <li>Check Dependencies: Verify no other processes are using the resources</li> <li>Monitor Cleanup: Watch for errors during cleanup process</li> </ol>"},{"location":"reference/user-guide/cleanup-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/cleanup-guide/#namespace-stuck-in-terminating","title":"Namespace Stuck in Terminating","text":"<p>Problem: Namespace remains in \"Terminating\" state</p> <p>Solution:</p> <pre><code># Check for finalizers\nkubectl get namespace kubevirt-perf-test-1 -o yaml | grep finalizers\n\n# Remove finalizers if stuck\nkubectl patch namespace kubevirt-perf-test-1 -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#pvc-not-deleting","title":"PVC Not Deleting","text":"<p>Problem: PVC stuck in \"Terminating\" state</p> <p>Solution:</p> <pre><code># Check if PVC is in use\nkubectl describe pvc &lt;pvc-name&gt; -n &lt;namespace&gt;\n\n# Delete associated pods/VMs first\nkubectl delete vm --all -n &lt;namespace&gt;\n\n# Force delete if needed\nkubectl patch pvc &lt;pvc-name&gt; -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/user-guide/cleanup-guide/#cleanup-fails-with-permission-errors","title":"Cleanup Fails with Permission Errors","text":"<p>Problem: Insufficient permissions to delete resources</p> <p>Solution: - Ensure your user has cluster-admin or equivalent permissions - Check RBAC policies: <code>kubectl auth can-i delete namespace</code> - Contact cluster administrator for required permissions</p>"},{"location":"reference/user-guide/cleanup-guide/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - All cleanup-related options</li> <li>Output and Results - Saving results before cleanup</li> <li>Best Practices - Cleanup best practices</li> </ul>"},{"location":"reference/user-guide/configuration/","title":"Configuration Options","text":"<p>This page provides a comprehensive reference for all configuration options available in the virtbench CLI and Python scripts.</p>"},{"location":"reference/user-guide/configuration/#vm-creation-tests","title":"VM Creation Tests","text":"<p>Configuration options for DataSource-based VM provisioning and boot storm tests.</p> Option Description Default <code>--start</code> Starting namespace index 1 <code>--end</code> Ending namespace index 100 <code>--vm-name</code> VM resource name rhel-9-vm <code>--concurrency</code> Max parallel monitoring threads 50 <code>--ssh-pod</code> Pod name for ping tests ssh-test-pod <code>--ssh-pod-ns</code> Namespace of SSH pod default <code>--poll-interval</code> Seconds between status checks 1 <code>--ping-timeout</code> Ping timeout in seconds 600 <code>--log-file</code> Output log file path stdout <code>--log-level</code> Logging level (DEBUG/INFO/WARNING/ERROR) INFO <code>--namespace-prefix</code> Prefix for test namespaces kubevirt-perf-test <code>--namespace-batch-size</code> Namespaces to create in parallel 20 <code>--boot-storm</code> Enable boot storm testing false <code>--single-node</code> Run all VMs on a single node false <code>--node-name</code> Specific node to use (requires --single-node) auto-select <code>--cleanup</code> Delete resources and namespaces after test false <code>--cleanup-on-failure</code> Clean up even if tests fail false <code>--dry-run-cleanup</code> Show what would be deleted without deleting false <code>--yes</code> Skip confirmation prompt for cleanup false <code>--save_results</code> Save detailed results (JSON and CSV) inside a timestamped folder under results/ folder false <code>--results_folder</code> Base directory to store test results ../results <code>--storage-version</code> Storage version to include in results path (optional) -"},{"location":"reference/user-guide/configuration/#live-migration-tests","title":"Live Migration Tests","text":"<p>Configuration options for VM live migration testing.</p> Option Description Default <code>--start</code> Starting namespace index 1 <code>--end</code> Ending namespace index 10 <code>--vm-name</code> VM resource name rhel-9-vm <code>--namespace-prefix</code> Prefix for test namespaces kubevirt-perf-test <code>--create-vms</code> Create VMs before migration false <code>--vm-template</code> VM template YAML file ../examples/vm-templates/vm-template.yaml <code>--single-node</code> Create all VMs on a single node (requires --create-vms) false <code>--node-name</code> Specific node to create VMs on (requires --single-node) auto-select <code>--source-node</code> Source node name for migration None <code>--target-node</code> Target node name for migration auto-select <code>--parallel</code> Migrate VMs in parallel false <code>--evacuate</code> Evacuate all VMs from source node false <code>--auto-select-busiest</code> Auto-select the node with most VMs (requires --evacuate) false <code>--round-robin</code> Migrate VMs in round-robin fashion across all nodes false <code>--concurrency</code> Number of concurrent migrations 10 <code>--migration-timeout</code> Timeout for each migration in seconds 600 <code>--max-migration-retries</code> Maximum retries for failed migrations 3 <code>--vm-startup-timeout</code> Timeout waiting for VMs to reach Running state 3600 (1 hour) <code>--ssh-pod</code> SSH test pod name for ping tests ssh-test-pod <code>--ssh-pod-ns</code> SSH test pod namespace default <code>--ping-timeout</code> Timeout for ping validation in seconds 3600 (1 hour) <code>--skip-ping</code> Skip ping validation after migration false <code>--interleaved-scheduling</code> Distribute parallel migration threads in interleaved pattern across nodes false <code>--log-file</code> Output log file path stdout <code>--log-level</code> Logging level (DEBUG/INFO/WARNING/ERROR) INFO <code>--cleanup</code> Delete VMs, VMIMs, and namespaces after test false <code>--cleanup-on-failure</code> Clean up resources even if tests fail false <code>--dry-run-cleanup</code> Show what would be deleted without deleting false <code>--yes</code> Skip confirmation prompt for cleanup false <code>--skip-checks</code> Skip VM verifications before migration false <code>--save-results</code> Save detailed migration results (JSON and CSV) under results/ false <code>--storage-version</code> Storage version to include in results path (optional) - <code>--results-folder</code> Base directory to store test results ../results"},{"location":"reference/user-guide/configuration/#failure-recovery-tests","title":"Failure Recovery Tests","text":"<p>Configuration options for failure and recovery testing with FAR.</p> Option Description Default <code>--start</code> Starting namespace index 1 <code>--end</code> Ending namespace index 5 <code>--vm-name</code> VMI resource name rhel-9-vm <code>--concurrency</code> Max parallel threads 10 <code>--ssh-pod</code> Pod name for ping tests ssh-test-pod <code>--ssh-pod-ns</code> Namespace of SSH pod default <code>--poll-interval</code> Seconds between polls 1 <code>--log-file</code> Output log file path stdout <code>--log-level</code> Logging level INFO"},{"location":"reference/user-guide/configuration/#capacity-benchmark-tests","title":"Capacity Benchmark Tests","text":"<p>Configuration options for capacity benchmark testing.</p>"},{"location":"reference/user-guide/configuration/#required-options","title":"Required Options","text":"Option Description <code>--storage-class</code> Storage class name (comma-separated for multiple)"},{"location":"reference/user-guide/configuration/#test-configuration","title":"Test Configuration","text":"Option Default Description <code>--namespace</code> <code>virt-capacity-benchmark</code> Namespace for test resources <code>--max-iterations</code> <code>0</code> (unlimited) Maximum number of iterations <code>--vms</code> <code>5</code> Number of VMs per iteration <code>--data-volume-count</code> <code>9</code> Number of data volumes per VM <code>--min-vol-size</code> <code>30Gi</code> Initial volume size <code>--min-vol-inc-size</code> <code>10Gi</code> Volume size increment for resize"},{"location":"reference/user-guide/configuration/#vm-template-configuration","title":"VM Template Configuration","text":"Option Default Description <code>--vm-yaml</code> <code>examples/vm-templates/vm-template.yaml</code> Path to VM YAML template <code>--vm-name</code> <code>rhel-9-vm</code> Base VM name <code>--datasource-name</code> <code>rhel9</code> DataSource name <code>--datasource-namespace</code> <code>openshift-virtualization-os-images</code> DataSource namespace <code>--vm-memory</code> <code>2048M</code> VM memory <code>--vm-cpu-cores</code> <code>1</code> VM CPU cores"},{"location":"reference/user-guide/configuration/#skip-options","title":"Skip Options","text":"Option Description <code>--skip-resize-job</code> Skip volume resize phase <code>--skip-snapshot-job</code> Skip snapshot phase <code>--skip-restart-job</code> Skip restart phase"},{"location":"reference/user-guide/configuration/#execution-options","title":"Execution Options","text":"Option Default Description <code>--concurrency</code> <code>10</code> Number of concurrent operations <code>--poll-interval</code> <code>5</code> Polling interval in seconds <code>--scheduling-timeout</code> <code>120</code> Seconds to wait in Scheduling state before declaring capacity reached"},{"location":"reference/user-guide/configuration/#cleanup-options","title":"Cleanup Options","text":"Option Description <code>--cleanup</code> Cleanup resources after test completion <code>--cleanup-only</code> Only cleanup resources from previous runs"},{"location":"reference/user-guide/configuration/#results-options","title":"Results Options","text":"Option Default Description <code>--save-results</code> <code>false</code> Save results to JSON/CSV files <code>--results-dir</code> <code>results</code> Directory to save results <code>--storage-version</code> <code>default</code> Storage version for folder hierarchy (e.g., 3.2.0) <p>Results are saved in the standard folder structure:</p> <pre><code>results/{storage-version}/{num-disks}-disk/{timestamp}_capacity_benchmark_{total_vms}vms/\n</code></pre>"},{"location":"reference/user-guide/configuration/#logging-options","title":"Logging Options","text":"Option Default Description <code>--log-file</code> Auto-generated Log file path <code>--log-level</code> <code>INFO</code> Logging level (DEBUG, INFO, WARNING, ERROR)"},{"location":"reference/user-guide/configuration/#common-options","title":"Common Options","text":"<p>These options are available across multiple test types:</p>"},{"location":"reference/user-guide/configuration/#logging","title":"Logging","text":"<ul> <li><code>--log-file</code>: Path to save log output (default: stdout)</li> <li><code>--log-level</code>: Set logging verbosity (DEBUG, INFO, WARNING, ERROR)</li> </ul>"},{"location":"reference/user-guide/configuration/#cleanup","title":"Cleanup","text":"<ul> <li><code>--cleanup</code>: Remove all test resources after completion</li> <li><code>--cleanup-on-failure</code>: Clean up even if tests fail</li> <li><code>--dry-run-cleanup</code>: Preview what would be deleted without actually deleting</li> <li><code>--yes</code>: Skip confirmation prompts</li> </ul>"},{"location":"reference/user-guide/configuration/#results","title":"Results","text":"<ul> <li><code>--save-results</code>: Save detailed results to JSON and CSV files</li> <li><code>--storage-version</code>: Organize results by storage version</li> <li><code>--results-folder</code> / <code>--results-dir</code>: Base directory for results</li> </ul>"},{"location":"reference/user-guide/configuration/#network-testing","title":"Network Testing","text":"<ul> <li><code>--ssh-pod</code>: Name of SSH test pod for ping validation</li> <li><code>--ssh-pod-ns</code>: Namespace of SSH test pod</li> <li><code>--ping-timeout</code>: Timeout for network reachability tests</li> <li><code>--skip-ping</code>: Skip network validation (faster but less comprehensive)</li> </ul>"},{"location":"reference/user-guide/configuration/#concurrency","title":"Concurrency","text":"<ul> <li><code>--concurrency</code>: Number of parallel operations</li> <li><code>--poll-interval</code>: Seconds between status checks</li> </ul>"},{"location":"reference/user-guide/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"reference/user-guide/configuration/#virtbench_repo","title":"VIRTBENCH_REPO","text":"<p>When using the virtbench CLI from any directory, set this variable to point to the repository root:</p> <pre><code>export VIRTBENCH_REPO=/path/to/kubevirt-benchmark-suite\n</code></pre> <p>Add to your shell profile for persistence:</p> <pre><code>echo 'export VIRTBENCH_REPO=/path/to/kubevirt-benchmark-suite' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"reference/user-guide/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"reference/user-guide/configuration/#vm-templates","title":"VM Templates","text":"<p>VM templates use placeholder variables that can be replaced:</p> Variable Description Example Values <code>{{VM_NAME}}</code> VM name <code>rhel-9-vm</code>, <code>my-test-vm</code> <code>{{STORAGE_CLASS_NAME}}</code> Storage class name <code>standard</code>, <code>gp2</code>, <code>ceph-rbd</code> <code>{{DATASOURCE_NAME}}</code> DataSource name <code>rhel9</code>, <code>fedora</code>, <code>centos</code> <code>{{DATASOURCE_NAMESPACE}}</code> DataSource namespace <code>openshift-virtualization-os-images</code> <code>{{STORAGE_SIZE}}</code> Root disk storage size <code>30Gi</code>, <code>50Gi</code>, <code>100Gi</code> <code>{{VM_MEMORY}}</code> VM memory allocation <code>2048M</code>, <code>4Gi</code>, <code>8Gi</code> <code>{{VM_CPU_CORES}}</code> Number of CPU cores <code>1</code>, <code>2</code>, <code>4</code>, <code>8</code> <p>See the Installation Guide for details on using the template helper script.</p>"},{"location":"reference/user-guide/configuration/#see-also","title":"See Also","text":"<ul> <li>User Guide Overview - Getting started with benchmarks</li> <li>Output and Results - Understanding test output</li> <li>Installation Guide - Setup and configuration</li> </ul>"},{"location":"reference/user-guide/output-and-results/","title":"Output and Results","text":"<p>This page explains how to interpret test output, understand results, and troubleshoot common issues.</p>"},{"location":"reference/user-guide/output-and-results/#console-output","title":"Console Output","text":"<p>Tests provide real-time progress updates:</p> <pre><code>[INFO] 2024-01-15 10:30:00 - Starting VM creation test\n[INFO] 2024-01-15 10:30:00 - Creating namespaces kubevirt-perf-test-1 to kubevirt-perf-test-100\n[INFO] 2024-01-15 10:30:05 - Dispatching VM creation in parallel\n[INFO] 2024-01-15 10:30:15 - [kubevirt-perf-test-1] VM Running at 8.45s\n[INFO] 2024-01-15 10:30:18 - [kubevirt-perf-test-1] Ping success at 11.23s\n...\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#summary-report","title":"Summary Report","text":"<p>At completion, a summary table is displayed:</p> <pre><code>Performance Test Summary\n================================================================================\nNamespace                Running(s)      Ping(s)         Status\n--------------------------------------------------------------------------------\nkubevirt-perf-test-1     8.45           11.23           Success\nkubevirt-perf-test-2     9.12           12.45           Success\nkubevirt-perf-test-3     8.89           11.98           Success\n...\n================================================================================\nStatistics:\n  Total VMs:              100\n  Successful:             98\n  Failed:                 2\n  Avg Time to Running:    9.23s\n  Avg Time to Ping:       12.45s\n  Max Time to Running:    15.67s\n  Max Time to Ping:       18.92s\n  Total Test Duration:    125.34s\n================================================================================\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#log-files","title":"Log Files","text":"<p>Detailed logs are saved to the specified log file with:</p> <ul> <li>Timestamps for all operations</li> <li>Error messages and stack traces</li> <li>Resource creation/deletion events</li> <li>Performance metrics</li> </ul>"},{"location":"reference/user-guide/output-and-results/#example-log-entry","title":"Example Log Entry","text":"<pre><code>[INFO] 2024-01-15 10:30:15 - [kubevirt-perf-test-1] VM created successfully\n[INFO] 2024-01-15 10:30:18 - [kubevirt-perf-test-1] VM reached Running state at 8.45s\n[INFO] 2024-01-15 10:30:21 - [kubevirt-perf-test-1] Ping successful at 11.23s\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#saved-results","title":"Saved Results","text":"<p>When using <code>--save-results</code>, tests generate structured output files:</p>"},{"location":"reference/user-guide/output-and-results/#file-structure","title":"File Structure","text":"<pre><code>results/\n\u251c\u2500\u2500 {storage-version}/\n\u2502   \u251c\u2500\u2500 {num-disks}-disk/\n\u2502   \u2502   \u251c\u2500\u2500 {timestamp}_vm_creation_{num_vms}vms/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 vm_creation_results.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 vm_creation_results.csv\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 summary_vm_creation.json\n\u2502   \u2502   \u251c\u2500\u2500 {timestamp}_migration_{num_vms}vms/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 migration_results.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 migration_results.csv\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 summary_migration.json\n\u2502   \u2502   \u2514\u2500\u2500 {timestamp}_capacity_benchmark_{total_vms}vms/\n\u2502   \u2502       \u251c\u2500\u2500 capacity_benchmark_results.json\n\u2502   \u2502       \u251c\u2500\u2500 capacity_benchmark_results.csv\n\u2502   \u2502       \u2514\u2500\u2500 summary_capacity_benchmark.json\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#json-results-format","title":"JSON Results Format","text":"<pre><code>{\n  \"test_type\": \"vm_creation\",\n  \"timestamp\": \"2024-01-15T10:30:00\",\n  \"total_vms\": 100,\n  \"successful\": 98,\n  \"failed\": 2,\n  \"avg_time_to_running\": 9.23,\n  \"avg_time_to_ping\": 12.45,\n  \"max_time_to_running\": 15.67,\n  \"max_time_to_ping\": 18.92,\n  \"results\": [\n    {\n      \"namespace\": \"kubevirt-perf-test-1\",\n      \"vm_name\": \"rhel-9-vm\",\n      \"time_to_running\": 8.45,\n      \"time_to_ping\": 11.23,\n      \"status\": \"Success\"\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#csv-results-format","title":"CSV Results Format","text":"<pre><code>namespace,vm_name,time_to_running,time_to_ping,status\nkubevirt-perf-test-1,rhel-9-vm,8.45,11.23,Success\nkubevirt-perf-test-2,rhel-9-vm,9.12,12.45,Success\nkubevirt-perf-test-3,rhel-9-vm,8.89,11.98,Success\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#understanding-metrics","title":"Understanding Metrics","text":""},{"location":"reference/user-guide/output-and-results/#vm-creation-metrics","title":"VM Creation Metrics","text":"<ul> <li>Time to Running: Duration from VM creation to Running state</li> <li>Includes: DataVolume provisioning, VM scheduling, VM startup</li> <li> <p>Good: &lt; 30s, Acceptable: 30-60s, Slow: &gt; 60s</p> </li> <li> <p>Time to Ping: Duration from VM creation to network reachability</p> </li> <li>Includes: Time to Running + cloud-init + network configuration</li> <li>Good: &lt; 60s, Acceptable: 60-120s, Slow: &gt; 120s</li> </ul>"},{"location":"reference/user-guide/output-and-results/#migration-metrics","title":"Migration Metrics","text":"<ul> <li>Migration Duration (Observed): Time measured by the test script</li> <li>Migration Duration (VMIM): Time recorded in VirtualMachineInstanceMigration resource</li> <li>Downtime: Time VM is unavailable during migration (if measured)</li> </ul>"},{"location":"reference/user-guide/output-and-results/#capacity-metrics","title":"Capacity Metrics","text":"<ul> <li>VMs Created: Total VMs successfully created across all iterations</li> <li>Iterations Completed: Number of successful iteration cycles</li> <li>Failure Point: Which phase failed (creation, resize, restart, snapshot)</li> <li>Time per Phase: Duration of each operation phase</li> </ul>"},{"location":"reference/user-guide/output-and-results/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/output-and-results/#common-issues","title":"Common Issues","text":""},{"location":"reference/user-guide/output-and-results/#vms-fail-to-reach-running-state","title":"VMs fail to reach Running state","text":"<p>Symptoms: VMs stuck in Scheduling or Pending state</p> <p>Solutions: - Check storage class is available: <code>kubectl get sc</code> - Verify sufficient cluster resources: <code>kubectl top nodes</code> - Check VM events: <code>kubectl describe vm &lt;vm-name&gt; -n &lt;namespace&gt;</code> - Review PVC status: <code>kubectl get pvc -n &lt;namespace&gt;</code></p>"},{"location":"reference/user-guide/output-and-results/#ping-tests-timeout","title":"Ping tests timeout","text":"<p>Symptoms: VMs reach Running state but ping fails</p> <p>Solutions: - Verify SSH pod exists and is running: <code>kubectl get pod &lt;ssh-pod&gt; -n &lt;namespace&gt;</code> - Check network policies allow pod-to-pod communication - Verify VM has cloud-init configured correctly - Check VM console for boot errors: <code>virtctl console &lt;vm-name&gt; -n &lt;namespace&gt;</code></p>"},{"location":"reference/user-guide/output-and-results/#permission-denied-errors","title":"Permission denied errors","text":"<p>Symptoms: Cannot create namespaces, VMs, or other resources</p> <p>Solutions: - Ensure your user has cluster-admin or equivalent permissions - Check RBAC policies: <code>kubectl auth can-i create vm --all-namespaces</code> - Verify service account permissions if running in a pod</p>"},{"location":"reference/user-guide/output-and-results/#golden-image-pvcs-not-ready","title":"Golden image PVCs not ready","text":"<p>Symptoms: DataSource or DataVolume not found</p> <p>Solutions: - Check DataVolume status: <code>kubectl get dv -n openshift-virtualization-os-images</code> - Verify registry image stream exists: <code>kubectl get imagestream -n openshift-virtualization-os-images</code> - Check CDI operator logs: <code>kubectl logs -n openshift-cnv -l name=cdi-operator</code></p>"},{"location":"reference/user-guide/output-and-results/#capacity-benchmark-issues","title":"Capacity Benchmark Issues","text":""},{"location":"reference/user-guide/output-and-results/#volume-resize-fails","title":"Volume resize fails","text":"<p>Symptoms: Resize phase fails with error</p> <p>Solutions: - Check if your storage class supports volume expansion:   <code>bash   kubectl get storageclass YOUR-STORAGE-CLASS -o jsonpath='{.allowVolumeExpansion}'</code> - If <code>false</code>, use <code>--skip-resize-job</code> to skip this phase - Check storage backend limits and quotas</p>"},{"location":"reference/user-guide/output-and-results/#snapshot-creation-fails","title":"Snapshot creation fails","text":"<p>Symptoms: Snapshot phase fails</p> <p>Solutions: - Check if VolumeSnapshotClass is configured:   <code>bash   kubectl get volumesnapshotclass</code> - If not available, use <code>--skip-snapshot-job</code> to skip this phase - Verify storage backend supports CSI snapshots</p>"},{"location":"reference/user-guide/output-and-results/#out-of-resources-vm-creation-fails","title":"Out of resources (VM creation fails)","text":"<p>Symptoms: VMs stuck in Scheduling state, capacity limit reached</p> <p>Solutions: - This indicates you've reached capacity limits. Check:   ```bash   # Check node resources   kubectl top nodes</p> <p># Check node status   kubectl describe node node-name   ``` - Review cluster resource quotas - Add more worker nodes or increase node resources</p>"},{"location":"reference/user-guide/output-and-results/#migration-issues","title":"Migration Issues","text":""},{"location":"reference/user-guide/output-and-results/#migration-stuck-or-timeout","title":"Migration stuck or timeout","text":"<p>Symptoms: Migration doesn't complete within timeout</p> <p>Solutions: - Increase <code>--migration-timeout</code> value - Check network bandwidth between nodes - Verify storage backend supports live migration - Check virt-handler logs on source and target nodes</p>"},{"location":"reference/user-guide/output-and-results/#migration-fails-immediately","title":"Migration fails immediately","text":"<p>Symptoms: Migration fails right after starting</p> <p>Solutions: - Verify VM is in Running state before migration - Check if VM has any conditions preventing migration - Review VMIM resource for error details: <code>kubectl describe vmim -n &lt;namespace&gt;</code></p>"},{"location":"reference/user-guide/output-and-results/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code># Using virtbench CLI\nvirtbench datasource-clone --log-level DEBUG --start 1 --end 5\n\n# Using Python script\npython3 measure-vm-creation-time.py --log-level DEBUG --start 1 --end 5\n</code></pre>"},{"location":"reference/user-guide/output-and-results/#performance-baselines","title":"Performance Baselines","text":""},{"location":"reference/user-guide/output-and-results/#expected-performance-ranges","title":"Expected Performance Ranges","text":"<p>These are general guidelines. Actual performance depends on your infrastructure:</p>"},{"location":"reference/user-guide/output-and-results/#vm-creation-datasource-clone","title":"VM Creation (DataSource Clone)","text":"Storage Type Time to Running Time to Ping Local SSD 10-20s 30-45s Network SSD (Portworx, Ceph) 15-30s 40-60s Network HDD 30-60s 60-120s"},{"location":"reference/user-guide/output-and-results/#live-migration","title":"Live Migration","text":"VM Size Migration Duration Small (2GB RAM) 10-30s Medium (4-8GB RAM) 30-60s Large (16GB+ RAM) 60-180s"},{"location":"reference/user-guide/output-and-results/#boot-storm-impact","title":"Boot Storm Impact","text":"<p>Expect 1.5-3x slower performance during boot storm compared to sequential creation.</p>"},{"location":"reference/user-guide/output-and-results/#best-practices","title":"Best Practices","text":"<ol> <li>Run Multiple Tests: Run tests multiple times to get consistent baselines</li> <li>Save Results: Always use <code>--save-results</code> to track performance over time</li> <li>Monitor Resources: Watch cluster resources during tests</li> <li>Start Small: Begin with small VM counts to validate setup</li> <li>Use Logging: Enable appropriate log levels for troubleshooting</li> <li>Clean Up: Always clean up test resources after completion</li> </ol>"},{"location":"reference/user-guide/output-and-results/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - All available configuration options</li> <li>Results Dashboard - Visualize test results</li> <li>User Guide - Running different test scenarios</li> </ul>"},{"location":"reference/user-guide/repository-structure/","title":"Repository Structure","text":"<p>This page describes the organization and structure of the virtbench repository.</p>"},{"location":"reference/user-guide/repository-structure/#directory-layout","title":"Directory Layout","text":"<pre><code>kubevirt-benchmark/\n\u251c\u2500\u2500 virtbench/                    # Main CLI package\n\u2502   \u251c\u2500\u2500 __init__.py              # Package initialization\n\u2502   \u251c\u2500\u2500 cli.py                   # CLI entry point and command definitions\n\u2502   \u251c\u2500\u2500 commands/                # Individual command implementations\n\u2502   \u2502   \u251c\u2500\u2500 datasource_clone.py # DataSource clone benchmark\n\u2502   \u2502   \u251c\u2500\u2500 migration.py         # Migration benchmark\n\u2502   \u2502   \u251c\u2500\u2500 capacity_benchmark.py# Capacity benchmark\n\u2502   \u2502   \u251c\u2500\u2500 failure_recovery.py  # Failure recovery benchmark\n\u2502   \u2502   \u2514\u2500\u2500 validate_cluster.py  # Cluster validation\n\u2502   \u2514\u2500\u2500 utils/                   # Shared utilities\n\u2502       \u251c\u2500\u2500 logger.py            # Logging utilities\n\u2502       \u251c\u2500\u2500 k8s_utils.py         # Kubernetes helpers\n\u2502       \u2514\u2500\u2500 results.py           # Results processing\n\u2502\n\u251c\u2500\u2500 scripts/                     # Legacy Python scripts (deprecated)\n\u2502   \u251c\u2500\u2500 measure-vm-creation-time.py\n\u2502   \u251c\u2500\u2500 measure-migration-time.py\n\u2502   \u251c\u2500\u2500 measure-capacity-benchmark.py\n\u2502   \u2514\u2500\u2500 measure-failure-recovery.py\n\u2502\n\u251c\u2500\u2500 dashboard/                   # Dashboard generation\n\u2502   \u251c\u2500\u2500 generate_dashboard.py   # Dashboard generator script\n\u2502   \u251c\u2500\u2500 cluster_info.yaml       # Cluster metadata template\n\u2502   \u2514\u2500\u2500 manual_results.yaml     # Manual results template\n\u2502\n\u251c\u2500\u2500 templates/                   # VM and resource templates\n\u2502   \u251c\u2500\u2500 vm-template.yaml        # Base VM template\n\u2502   \u251c\u2500\u2500 datasource-template.yaml# DataSource template\n\u2502   \u2514\u2500\u2500 far-template.yaml       # FAR template\n\u2502\n\u251c\u2500\u2500 docs/                        # Documentation\n\u2502   \u251c\u2500\u2500 index.md                # Landing page\n\u2502   \u251c\u2500\u2500 install.md              # Installation guide\n\u2502   \u251c\u2500\u2500 reference/              # Reference documentation\n\u2502   \u2502   \u251c\u2500\u2500 user-guide/         # User guides\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test-scenarios/ # Test scenario guides\n\u2502   \u2502   \u251c\u2500\u2500 configuration.md    # Configuration reference\n\u2502   \u2502   \u251c\u2500\u2500 output-and-results.md\n\u2502   \u2502   \u2514\u2500\u2500 results-dashboard.md\n\u2502   \u2514\u2500\u2500 community/              # Community docs\n\u2502\n\u251c\u2500\u2500 results/                     # Test results (auto-generated)\n\u2502   \u2514\u2500\u2500 {storage-version}/\n\u2502       \u2514\u2500\u2500 {num-disks}-disk/\n\u2502           \u2514\u2500\u2500 {timestamp}_{test}_{vms}vms/\n\u2502\n\u251c\u2500\u2500 setup.py                     # Python package setup\n\u251c\u2500\u2500 requirements.txt             # Python dependencies\n\u251c\u2500\u2500 install.sh                   # Installation script\n\u251c\u2500\u2500 mkdocs.yml                   # Documentation configuration\n\u251c\u2500\u2500 README.md                    # Repository README\n\u251c\u2500\u2500 LICENSE                      # Apache 2.0 license\n\u2514\u2500\u2500 CHANGELOG.md                 # Version history\n</code></pre>"},{"location":"reference/user-guide/repository-structure/#key-components","title":"Key Components","text":""},{"location":"reference/user-guide/repository-structure/#virtbench-cli-package","title":"virtbench CLI Package","text":"<p>The <code>virtbench/</code> directory contains the main CLI application:</p> <ul> <li>cli.py: Main entry point using Click framework</li> <li>commands/: Individual benchmark command implementations</li> <li>utils/: Shared utility functions for Kubernetes operations, logging, and results processing</li> </ul>"},{"location":"reference/user-guide/repository-structure/#templates","title":"Templates","text":"<p>The <code>templates/</code> directory contains YAML templates for:</p> <ul> <li>VM templates: Base VM configurations for different scenarios</li> <li>DataSource templates: For VM cloning operations</li> <li>FAR templates: For failure and recovery testing</li> </ul>"},{"location":"reference/user-guide/repository-structure/#dashboard","title":"Dashboard","text":"<p>The <code>dashboard/</code> directory contains tools for generating interactive HTML dashboards from test results.</p>"},{"location":"reference/user-guide/repository-structure/#documentation","title":"Documentation","text":"<p>The <code>docs/</code> directory contains all documentation in Markdown format, organized for MkDocs:</p> <ul> <li>Getting Started: Installation and quick start guides</li> <li>Reference: Detailed guides and configuration reference</li> <li>Community: Contributing guidelines and support information</li> </ul>"},{"location":"reference/user-guide/repository-structure/#results-directory","title":"Results Directory","text":"<p>The <code>results/</code> directory is auto-generated when running tests with <code>--save-results</code>. It follows a hierarchical structure:</p> <pre><code>results/\n\u251c\u2500\u2500 {storage-version}/          # e.g., \"3.2.0\" or \"default\"\n\u2502   \u251c\u2500\u2500 {num-disks}-disk/       # e.g., \"1-disk\", \"2-disk\"\n\u2502   \u2502   \u251c\u2500\u2500 {timestamp}_{test}_{vms}vms/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 *_results.json  # Detailed results\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 *_results.csv   # CSV format\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 summary_*.json  # Summary statistics\n</code></pre>"},{"location":"reference/user-guide/repository-structure/#file-naming-conventions","title":"File Naming Conventions","text":""},{"location":"reference/user-guide/repository-structure/#test-results","title":"Test Results","text":"<ul> <li>Timestamp format: <code>YYYYMMDD-HHMMSS</code></li> <li>Test names: <code>vm_creation</code>, <code>boot_storm</code>, <code>migration</code>, <code>capacity_benchmark</code>, <code>failure_recovery</code></li> <li>VM range: <code>{start}-{end}</code> (e.g., <code>1-50</code>)</li> </ul> <p>Example: <code>20250105-143052_vm_creation_1-50vms/</code></p>"},{"location":"reference/user-guide/repository-structure/#configuration-files","title":"Configuration Files","text":"<ul> <li>YAML files: Use <code>.yaml</code> extension</li> <li>Python files: Follow PEP 8 naming conventions</li> <li>Shell scripts: Use <code>.sh</code> extension</li> </ul>"},{"location":"reference/user-guide/repository-structure/#package-structure","title":"Package Structure","text":""},{"location":"reference/user-guide/repository-structure/#python-package","title":"Python Package","text":"<p>The virtbench package is installed as an editable package using <code>pip install -e .</code>:</p> <ul> <li>Entry point: <code>virtbench</code> command</li> <li>Version: Defined in <code>virtbench/__init__.py</code></li> <li>Dependencies: Listed in <code>requirements.txt</code> and <code>setup.py</code></li> </ul>"},{"location":"reference/user-guide/repository-structure/#dependencies","title":"Dependencies","text":"<p>Core dependencies: - click: CLI framework - rich: Terminal formatting and progress bars - pandas: Data processing and CSV generation - pyyaml: YAML file parsing</p>"},{"location":"reference/user-guide/repository-structure/#configuration-files_1","title":"Configuration Files","text":""},{"location":"reference/user-guide/repository-structure/#mkdocsyml","title":"mkdocs.yml","text":"<p>MkDocs configuration for documentation site: - Site metadata - Navigation structure - Theme configuration - Plugin settings</p>"},{"location":"reference/user-guide/repository-structure/#setuppy","title":"setup.py","text":"<p>Python package configuration: - Package metadata - Entry points for CLI commands - Dependency specifications - Python version requirements</p>"},{"location":"reference/user-guide/repository-structure/#requirementstxt","title":"requirements.txt","text":"<p>Python dependencies with version constraints: - Core libraries - CLI dependencies - Dashboard dependencies</p>"},{"location":"reference/user-guide/repository-structure/#see-also","title":"See Also","text":"<ul> <li>Installation Guide - How to install virtbench</li> <li>Configuration Options - Configuration reference</li> <li>Output and Results - Results structure and format</li> </ul>"},{"location":"reference/user-guide/results-dashboard/","title":"Results Dashboard","text":"<p>The virtbench suite includes an interactive HTML dashboard generator to visualize and analyze your performance test results.</p>"},{"location":"reference/user-guide/results-dashboard/#overview","title":"Overview","text":"<p>After running tests with <code>--save-results</code>, you can generate a rich, interactive dashboard that provides:</p> <ul> <li>Multi-level Organization: Results organized by Storage Version \u2192 Disk Count \u2192 VM Size</li> <li>Interactive Charts: Plotly-based bar charts showing duration metrics</li> <li>Detailed Tables: Sortable and searchable DataTables for all test results</li> <li>Cluster Information: Display cluster metadata and configuration</li> <li>Manual Results: Include manually collected test results</li> <li>Time-series Visualization: Track performance trends over time</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#generating-the-dashboard","title":"Generating the Dashboard","text":""},{"location":"reference/user-guide/results-dashboard/#basic-usage","title":"Basic Usage","text":"<pre><code># Generate dashboard for last 15 days of results\npython3 dashboard/generate_dashboard.py\n</code></pre> <p>This will: 1. Scan the <code>results/</code> directory for test results 2. Process all results from the last 15 days 3. Generate <code>results_dashboard.html</code> in the current directory</p>"},{"location":"reference/user-guide/results-dashboard/#custom-configuration","title":"Custom Configuration","text":"<pre><code># Custom time range and configuration\npython3 dashboard/generate_dashboard.py \\\n  --days 50 \\\n  --base-dir results \\\n  --cluster-info dashboard/cluster_info.yaml \\\n  --manual-results dashboard/manual_results.yaml \\\n  --output-html results_dashboard.html\n</code></pre>"},{"location":"reference/user-guide/results-dashboard/#dashboard-options","title":"Dashboard Options","text":"Option Description Default <code>--days</code> Number of days of results to include 15 <code>--base-dir</code> Base directory containing test results <code>results</code> <code>--cluster-info</code> Path to cluster information YAML file <code>dashboard/cluster_info.yaml</code> <code>--manual-results</code> Path to manual results YAML file <code>dashboard/manual_results.yaml</code> <code>--output-html</code> Output HTML file path <code>results_dashboard.html</code>"},{"location":"reference/user-guide/results-dashboard/#dashboard-features","title":"Dashboard Features","text":""},{"location":"reference/user-guide/results-dashboard/#vm-creation-performance","title":"VM Creation Performance","text":"<ul> <li>Charts: Bar charts showing average time to Running and time to Ping</li> <li>Tables: Detailed results for each test run with sortable columns</li> <li>Metrics: Success rate, average times, max times, total VMs tested</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#boot-storm-performance","title":"Boot Storm Performance","text":"<ul> <li>Comparison Charts: Initial creation vs boot storm performance</li> <li>Impact Analysis: Performance degradation metrics</li> <li>Statistics: Separate metrics for initial and boot storm phases</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#live-migration-performance","title":"Live Migration Performance","text":"<ul> <li>Duration Charts: Migration time analysis</li> <li>Success Rates: Migration completion statistics</li> <li>Detailed Metrics: Observed vs VMIM timestamps, downtime measurements</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#capacity-benchmark-results","title":"Capacity Benchmark Results","text":"<ul> <li>Capacity Limits: Maximum VMs created before failure</li> <li>Phase Analysis: Performance of each phase (create, resize, restart, snapshot)</li> <li>Iteration Metrics: Results across multiple iterations</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#cluster-information","title":"Cluster Information","text":"<p>Create a <code>cluster_info.yaml</code> file to include cluster metadata in the dashboard:</p> <pre><code>cluster_name: \"Production OCP Cluster\"\nocp_version: \"4.14.8\"\nkubevirt_version: \"4.14.2\"\nstorage_backend: \"Portworx Enterprise\"\nstorage_version: \"3.2.0\"\nnode_count: 6\nworker_nodes:\n  - name: \"worker-1\"\n    cpu: \"32 cores\"\n    memory: \"128 GB\"\n    storage: \"2TB NVMe\"\n  - name: \"worker-2\"\n    cpu: \"32 cores\"\n    memory: \"128 GB\"\n    storage: \"2TB NVMe\"\nnetwork: \"10 Gbps\"\nnotes: \"Production cluster with HA configuration\"\n</code></pre>"},{"location":"reference/user-guide/results-dashboard/#manual-results","title":"Manual Results","text":"<p>Include manually collected results in <code>manual_results.yaml</code>:</p> <pre><code>manual_tests:\n  - test_type: \"vm_creation\"\n    date: \"2024-01-15\"\n    storage_version: \"3.1.0\"\n    disk_count: 10\n    vm_count: 100\n    avg_time_to_running: 12.5\n    avg_time_to_ping: 18.3\n    notes: \"Baseline test before upgrade\"\n\n  - test_type: \"migration\"\n    date: \"2024-01-16\"\n    storage_version: \"3.1.0\"\n    vm_count: 50\n    avg_migration_duration: 25.4\n    success_rate: 100\n    notes: \"Sequential migration test\"\n</code></pre>"},{"location":"reference/user-guide/results-dashboard/#dashboard-sections","title":"Dashboard Sections","text":""},{"location":"reference/user-guide/results-dashboard/#1-cluster-overview","title":"1. Cluster Overview","text":"<p>Displays cluster configuration and metadata from <code>cluster_info.yaml</code>.</p>"},{"location":"reference/user-guide/results-dashboard/#2-test-summary","title":"2. Test Summary","text":"<p>High-level statistics across all test types: - Total tests run - Date range of results - Success rates - Performance trends</p>"},{"location":"reference/user-guide/results-dashboard/#3-vm-creation-results","title":"3. VM Creation Results","text":"<p>Organized by storage version and disk count: - Interactive charts for time to Running and time to Ping - Detailed tables with all test runs - Filtering and sorting capabilities</p>"},{"location":"reference/user-guide/results-dashboard/#4-boot-storm-results","title":"4. Boot Storm Results","text":"<p>Comparison between initial creation and boot storm: - Side-by-side performance charts - Performance degradation metrics - Statistical analysis</p>"},{"location":"reference/user-guide/results-dashboard/#5-migration-results","title":"5. Migration Results","text":"<p>Migration performance analysis: - Duration charts - Success rate tracking - Detailed migration metrics</p>"},{"location":"reference/user-guide/results-dashboard/#6-capacity-benchmark-results","title":"6. Capacity Benchmark Results","text":"<p>Capacity testing outcomes: - Maximum capacity reached - Phase-by-phase performance - Failure point analysis</p>"},{"location":"reference/user-guide/results-dashboard/#using-the-dashboard","title":"Using the Dashboard","text":""},{"location":"reference/user-guide/results-dashboard/#navigation","title":"Navigation","text":"<ul> <li>Use the table of contents to jump to specific sections</li> <li>Click on chart elements for detailed information</li> <li>Use table search and sort features to find specific results</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#filtering-results","title":"Filtering Results","text":"<ul> <li>Filter by storage version</li> <li>Filter by disk count</li> <li>Filter by date range</li> <li>Filter by test type</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#exporting-data","title":"Exporting Data","text":"<ul> <li>Tables can be copied to clipboard</li> <li>Export to CSV or Excel</li> <li>Print-friendly view available</li> </ul>"},{"location":"reference/user-guide/results-dashboard/#best-practices","title":"Best Practices","text":"<ol> <li>Regular Generation: Generate dashboard after each test run to track trends</li> <li>Version Tracking: Use <code>--storage-version</code> to organize results by storage backend version</li> <li>Cluster Info: Keep <code>cluster_info.yaml</code> updated with current configuration</li> <li>Manual Results: Document baseline tests and special scenarios</li> <li>Archive Dashboards: Save dashboard HTML files for historical reference</li> </ol>"},{"location":"reference/user-guide/results-dashboard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/results-dashboard/#no-results-found","title":"No results found","text":"<p>Cause: Results directory is empty or doesn't contain recent results</p> <p>Solution: - Verify results directory path with <code>--base-dir</code> - Increase <code>--days</code> to include older results - Ensure tests were run with <code>--save-results</code> flag</p>"},{"location":"reference/user-guide/results-dashboard/#dashboard-generation-fails","title":"Dashboard generation fails","text":"<p>Cause: Missing dependencies or malformed result files</p> <p>Solution: - Install required Python packages: <code>pip install -r requirements.txt</code> - Check result JSON files for syntax errors - Review dashboard script logs for specific errors</p>"},{"location":"reference/user-guide/results-dashboard/#charts-not-displaying","title":"Charts not displaying","text":"<p>Cause: JavaScript errors or missing Plotly library</p> <p>Solution: - Open browser console to check for errors - Ensure internet connection (Plotly loads from CDN) - Try a different web browser</p>"},{"location":"reference/user-guide/results-dashboard/#see-also","title":"See Also","text":"<ul> <li>Output and Results - Understanding test output</li> <li>Configuration Options - Test configuration reference</li> <li>User Guide - Running performance tests</li> </ul>"},{"location":"reference/user-guide/vm-template-guide/","title":"VM Template Guide","text":"<p>This guide explains how to use and customize VM templates for KubeVirt performance testing.</p>"},{"location":"reference/user-guide/vm-template-guide/#overview","title":"Overview","text":"<p>VM templates are YAML files that define the configuration for KubeVirt VirtualMachine resources. The virtbench suite includes several pre-configured templates and supports custom templates.</p>"},{"location":"reference/user-guide/vm-template-guide/#available-templates","title":"Available Templates","text":"<p>The repository includes the following templates in <code>examples/vm-templates/</code>:</p>"},{"location":"reference/user-guide/vm-template-guide/#1-vm-templateyaml-recommended","title":"1. vm-template.yaml (Recommended)","text":"<p>A flexible template with placeholder variables for easy customization.</p> <p>Template Variables: - <code>{{VM_NAME}}</code> - VM name - <code>{{STORAGE_CLASS_NAME}}</code> - Storage class name - <code>{{DATASOURCE_NAME}}</code> - DataSource name (e.g., rhel9, fedora) - <code>{{DATASOURCE_NAMESPACE}}</code> - DataSource namespace - <code>{{STORAGE_SIZE}}</code> - Root disk storage size (e.g., 30Gi) - <code>{{VM_MEMORY}}</code> - VM memory (e.g., 2048M, 4Gi) - <code>{{VM_CPU_CORES}}</code> - Number of CPU cores</p>"},{"location":"reference/user-guide/vm-template-guide/#2-rhel9-vm-datasourceyaml","title":"2. rhel9-vm-datasource.yaml","text":"<p>Pre-configured template for RHEL 9 VMs using DataSource cloning.</p> <p>Features: - Uses RHEL 9 DataSource from <code>openshift-virtualization-os-images</code> - 30Gi root disk - 2Gi memory, 1 CPU core - Cloud-init configuration included</p>"},{"location":"reference/user-guide/vm-template-guide/#3-rhel9-vm-registryyaml","title":"3. rhel9-vm-registry.yaml","text":"<p>Template for RHEL 9 VMs using PVC cloning from golden images.</p> <p>Features: - Clones from golden image PVC - Suitable for environments without DataSource support - Same resource configuration as datasource template</p>"},{"location":"reference/user-guide/vm-template-guide/#using-templates","title":"Using Templates","text":""},{"location":"reference/user-guide/vm-template-guide/#with-virtbench-cli","title":"With virtbench CLI","text":"<p>The virtbench CLI automatically handles template variable replacement:</p> <pre><code>virtbench datasource-clone \\\n  --start 1 \\\n  --end 10 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vm-template examples/vm-templates/vm-template.yaml\n</code></pre> <p>The CLI will automatically replace <code>{{STORAGE_CLASS_NAME}}</code> with your specified storage class.</p>"},{"location":"reference/user-guide/vm-template-guide/#with-template-helper-script","title":"With Template Helper Script","text":"<p>For manual template customization, use the <code>apply_template.sh</code> script:</p> <pre><code># Basic usage\n./utils/apply_template.sh \\\n  -o my-vm.yaml \\\n  -n my-vm \\\n  -s YOUR-STORAGE-CLASS\n\n# Full customization\n./utils/apply_template.sh \\\n  -o custom-vm.yaml \\\n  -n custom-vm \\\n  -s YOUR-STORAGE-CLASS \\\n  -d fedora \\\n  --storage-size 50Gi \\\n  --memory 4Gi \\\n  --cpu-cores 2\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#manual-replacement","title":"Manual Replacement","text":"<p>You can also manually replace placeholders using <code>sed</code>:</p> <pre><code>sed -i 's/{{STORAGE_CLASS_NAME}}/YOUR-STORAGE-CLASS/g' vm-template.yaml\nsed -i 's/{{VM_NAME}}/my-vm/g' vm-template.yaml\nkubectl apply -f vm-template.yaml -n my-namespace\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#template-structure","title":"Template Structure","text":""},{"location":"reference/user-guide/vm-template-guide/#basic-vm-template-structure","title":"Basic VM Template Structure","text":"<pre><code>apiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: {{VM_NAME}}\nspec:\n  dataVolumeTemplates:\n    - metadata:\n        name: {{VM_NAME}}-volume\n      spec:\n        sourceRef:\n          kind: DataSource\n          name: {{DATASOURCE_NAME}}\n          namespace: {{DATASOURCE_NAMESPACE}}\n        storage:\n          resources:\n            requests:\n              storage: {{STORAGE_SIZE}}\n          storageClassName: {{STORAGE_CLASS_NAME}}\n          volumeMode: Block\n  runStrategy: Always\n  template:\n    spec:\n      domain:\n        cpu:\n          cores: {{VM_CPU_CORES}}\n        devices:\n          disks:\n            - name: rootdisk\n              bootOrder: 1\n              disk:\n                bus: virtio\n            - name: cloudinitdisk\n              disk:\n                bus: virtio\n          interfaces:\n            - name: default\n              masquerade: {}\n        resources:\n          requests:\n            cpu: {{VM_CPU_CORES}}\n            memory: {{VM_MEMORY}}\n      networks:\n        - name: default\n          pod: {}\n      volumes:\n        - dataVolume:\n            name: {{VM_NAME}}-volume\n          name: rootdisk\n        - cloudInitNoCloud:\n            userData: |\n              #cloud-config\n              chpasswd:\n                expire: false\n              password: Password1\n              user: rhel\n          name: cloudinitdisk\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#customizing-templates","title":"Customizing Templates","text":""},{"location":"reference/user-guide/vm-template-guide/#changing-vm-resources","title":"Changing VM Resources","text":"<p>Modify CPU and memory allocations:</p> <pre><code>resources:\n  requests:\n    cpu: \"4\"        # 4 CPU cores\n    memory: 8Gi     # 8GB memory\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#changing-storage-size","title":"Changing Storage Size","text":"<p>Adjust root disk size:</p> <pre><code>storage:\n  resources:\n    requests:\n      storage: 100Gi  # 100GB disk\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#using-different-datasources","title":"Using Different DataSources","text":"<p>Change the source image:</p> <pre><code>sourceRef:\n  kind: DataSource\n  name: fedora      # Use Fedora instead of RHEL\n  namespace: openshift-virtualization-os-images\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#adding-node-selectors","title":"Adding Node Selectors","text":"<p>Pin VMs to specific nodes:</p> <pre><code>spec:\n  template:\n    spec:\n      nodeSelector:\n        kubernetes.io/hostname: worker-node-1\n</code></pre>"},{"location":"reference/user-guide/vm-template-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Use Template Variables: Prefer <code>vm-template.yaml</code> with placeholders for flexibility</li> <li>Version Control: Keep custom templates in version control</li> <li>Test Templates: Validate templates with a single VM before large-scale tests</li> <li>Resource Sizing: Match VM resources to your test requirements</li> <li>Storage Class: Ensure storage class supports required features (snapshots, resize, etc.)</li> </ol>"},{"location":"reference/user-guide/vm-template-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/vm-template-guide/#template-variable-not-replaced","title":"Template Variable Not Replaced","text":"<p>Problem: Placeholder like <code>{{STORAGE_CLASS_NAME}}</code> appears in created resources</p> <p>Solution: Ensure you're using the correct template application method or manually replace placeholders</p>"},{"location":"reference/user-guide/vm-template-guide/#datasource-not-found","title":"DataSource Not Found","text":"<p>Problem: VM creation fails with \"DataSource not found\"</p> <p>Solution:  - Verify DataSource exists: <code>kubectl get datasource -n openshift-virtualization-os-images</code> - Check DataSource name and namespace in template</p>"},{"location":"reference/user-guide/vm-template-guide/#storage-class-not-found","title":"Storage Class Not Found","text":"<p>Problem: PVC creation fails with \"StorageClass not found\"</p> <p>Solution: - List available storage classes: <code>kubectl get storageclass</code> - Update template with correct storage class name</p>"},{"location":"reference/user-guide/vm-template-guide/#see-also","title":"See Also","text":"<ul> <li>DataSource Clone Testing - Using templates in tests</li> <li>Configuration Options - Template-related options</li> <li>Cluster Validation - Verify DataSource availability</li> </ul>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/","title":"Capacity Benchmark Testing","text":"<p>Tests cluster capacity limits by running comprehensive VM operations in a loop until failure.</p> <p>Use Case: Discover maximum VM capacity, test volume expansion limits, validate snapshot functionality, and stress-test the cluster.</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#how-it-works","title":"How It Works","text":"<p>The capacity benchmark test runs in iterations, with each iteration performing:</p> <ol> <li>Phase 1: Creates VMs with multiple data volumes</li> <li>Phase 2: Resizes root and data volumes (tests volume expansion)</li> <li>Phase 3: Restarts VMs (tests VM lifecycle)</li> <li>Phase 4: Creates VM snapshots (tests snapshot functionality)</li> <li>Repeats until failure or max iterations reached</li> </ol>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#basic-capacity-test","title":"Basic Capacity Test","text":""},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-virtbench-cli","title":"Using virtbench CLI","text":"<pre><code># Run capacity test with default settings (5 VMs per iteration)\nvirtbench capacity-benchmark --storage-class YOUR-STORAGE-CLASS\n\n# Run with custom VM count\nvirtbench capacity-benchmark --storage-class YOUR-STORAGE-CLASS --vms 10\n\n# Run with maximum iterations limit\nvirtbench capacity-benchmark --storage-class YOUR-STORAGE-CLASS --max-iterations 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-python-script","title":"Using Python Script","text":"<pre><code>cd capacity-benchmark\n\n# Run capacity test with default settings (5 VMs per iteration)\npython3 measure-capacity.py --storage-class YOUR-STORAGE-CLASS\n\n# Run with custom VM count\npython3 measure-capacity.py --storage-class YOUR-STORAGE-CLASS --vms 10\n\n# Run with maximum iterations limit\npython3 measure-capacity.py --storage-class YOUR-STORAGE-CLASS --max-iterations 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#skip-specific-phases","title":"Skip Specific Phases","text":"<p>You can skip specific test phases to focus on particular aspects of capacity testing.</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-virtbench-cli_1","title":"Using virtbench CLI","text":"<pre><code># Test only VM creation capacity (skip resize, restart, snapshot, migration)\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 10 \\\n  --skip-resize-job \\\n  --skip-restart-job \\\n  --skip-snapshot-job\n\n# Test volume expansion limits\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --min-vol-size 30Gi \\\n  --min-vol-inc-size 20Gi \\\n  --max-iterations 10\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-python-script_1","title":"Using Python Script","text":"<pre><code>cd capacity-benchmark\n\n# Test only VM creation capacity (skip resize, restart, snapshot)\npython3 measure-capacity.py \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 10 \\\n  --skip-resize-job \\\n  --skip-restart-job \\\n  --skip-snapshot-job\n\n# Test volume expansion limits\npython3 measure-capacity.py \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --min-vol-size 30Gi \\\n  --min-vol-inc-size 20Gi \\\n  --max-iterations 10\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#save-results-to-files","title":"Save Results to Files","text":""},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-virtbench-cli_2","title":"Using virtbench CLI","text":"<pre><code># Run capacity test and save results\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --save-results\n\n# Save results with storage version for dashboard organization\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --save-results \\\n  --storage-version 3.2.0\n</code></pre> <p>Results will be saved to:</p> <pre><code>results/{storage-version}/{num-disks}-disk/{timestamp}_capacity_benchmark_{total_vms}vms/\n</code></pre> <p>Example:</p> <pre><code>results/3.2.0/10-disk/20251207-083451_capacity_benchmark_22vms/\n</code></pre> <p>Files created: - <code>capacity_benchmark_results.json</code> (detailed results) - <code>summary_capacity_benchmark.json</code> (summary for dashboard) - <code>capacity_benchmark_results.csv</code> (key metrics)</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-python-script_2","title":"Using Python Script","text":"<pre><code>cd capacity-benchmark\npython3 measure-capacity.py \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vms 5 \\\n  --save-results \\\n  --storage-version 3.2.0\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#custom-vm-template","title":"Custom VM Template","text":"<pre><code># Use custom VM template\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vm-yaml /path/to/custom-vm-template.yaml \\\n  --vms 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#custom-datasource","title":"Custom DataSource","text":"<pre><code># Use different DataSource\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --datasource-name fedora \\\n  --datasource-namespace openshift-virtualization-os-images \\\n  --vms 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#custom-vm-resources","title":"Custom VM Resources","text":"<pre><code># Configure VM memory and CPU\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --vm-memory 4Gi \\\n  --vm-cpu-cores 2 \\\n  --vms 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#custom-data-volume-configuration","title":"Custom Data Volume Configuration","text":"<pre><code># Configure number of data volumes and sizes\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --data-volume-count 5 \\\n  --min-vol-size 50Gi \\\n  --min-vol-inc-size 25Gi \\\n  --vms 3\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#concurrency-and-timeouts","title":"Concurrency and Timeouts","text":"<pre><code># Configure parallel operations and timeouts\nvirtbench capacity-benchmark \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --concurrency 20 \\\n  --poll-interval 10 \\\n  --scheduling-timeout 180 \\\n  --vms 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#cleanup","title":"Cleanup","text":""},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-virtbench-cli_3","title":"Using virtbench CLI","text":"<pre><code># Cleanup resources after test\nvirtbench capacity-benchmark --cleanup-only\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#using-python-script_3","title":"Using Python Script","text":"<pre><code>cd capacity-benchmark\npython3 measure-capacity.py --cleanup-only\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#understanding-results","title":"Understanding Results","text":"<p>The capacity benchmark provides detailed metrics for each iteration:</p> <ul> <li>VMs Created: Number of VMs successfully created</li> <li>Volumes Resized: Number of volumes successfully expanded</li> <li>VMs Restarted: Number of VMs successfully restarted</li> <li>Snapshots Created: Number of snapshots successfully created</li> <li>Time per Phase: Duration of each phase</li> <li>Failure Point: Which phase failed and why (if applicable)</li> </ul>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#interpreting-capacity-limits","title":"Interpreting Capacity Limits","text":"<p>The test stops when:</p> <ol> <li>Scheduling Timeout: VMs stuck in \"Scheduling\" state (resource exhaustion)</li> <li>Volume Resize Failure: Storage backend cannot expand volumes</li> <li>Snapshot Failure: Snapshot creation fails</li> <li>Max Iterations Reached: Configured limit reached</li> </ol>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#best-practices","title":"Best Practices","text":"<ol> <li>Start Small: Begin with 5 VMs per iteration to understand baseline</li> <li>Monitor Resources: Watch cluster resource utilization during tests</li> <li>Storage Limits: Be aware of storage quota and IOPS limits</li> <li>Cleanup: Always cleanup after tests to free resources</li> <li>Save Results: Use <code>--save-results</code> to track capacity over time</li> </ol>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#vms-stuck-in-scheduling","title":"VMs Stuck in Scheduling","text":"<p>Cause: Insufficient cluster resources (CPU, memory, or storage)</p> <p>Solution: - Check node resource availability - Reduce VM count per iteration - Add more worker nodes</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#volume-resize-failures","title":"Volume Resize Failures","text":"<p>Cause: Storage class doesn't support volume expansion</p> <p>Solution: - Verify <code>AllowVolumeExpansion: true</code> in StorageClass - Use <code>--skip-resize-job</code> to skip this phase - Check storage backend limits</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#snapshot-failures","title":"Snapshot Failures","text":"<p>Cause: Storage provisioner doesn't support CSI snapshots</p> <p>Solution: - Verify VolumeSnapshotClass exists - Use <code>--skip-snapshot-job</code> to skip this phase - Check storage backend snapshot support</p>"},{"location":"reference/user-guide/test-scenarios/capacity-benchmark/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - Detailed configuration reference</li> <li>Output and Results - Understanding test output</li> <li>Results Dashboard - Visualize capacity results</li> </ul>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/","title":"Cluster Validation","text":"<p>The cluster validation script checks that your OpenShift cluster is properly configured and ready to run KubeVirt performance tests.</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#validation-checks","title":"Validation Checks","text":"<p>The script validates:</p> <ul> <li>kubectl access and cluster connectivity</li> <li>OpenShift Virtualization installation and health</li> <li>KubeVirt resource status (Deployed phase)</li> <li>Critical deployments: virt-api, virt-controller, virt-operator</li> <li>virt-handler daemonset on all nodes</li> <li>Storage class availability</li> <li>Worker node readiness</li> <li>DataSource availability</li> <li>User permissions</li> <li>Node resource utilization</li> </ul>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#running-validation","title":"Running Validation","text":""},{"location":"reference/user-guide/test-scenarios/cluster-validation/#using-virtbench-cli","title":"Using virtbench CLI","text":"<pre><code># Basic validation\nvirtbench validate-cluster --storage-class YOUR-STORAGE-CLASS\n\n# Comprehensive validation\nvirtbench validate-cluster --storage-class YOUR-STORAGE-CLASS --all\n\n# With custom DataSource\nvirtbench validate-cluster \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --datasource fedora \\\n  --datasource-namespace openshift-virtualization-os-images\n\n# Require minimum worker nodes\nvirtbench validate-cluster \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --min-worker-nodes 5\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#using-python-script","title":"Using Python Script","text":"<pre><code>cd utils\n\n# Basic validation\npython3 validate_cluster.py --storage-class YOUR-STORAGE-CLASS\n\n# Comprehensive validation\npython3 validate_cluster.py --all --storage-class YOUR-STORAGE-CLASS\n\n# With custom DataSource\npython3 validate_cluster.py \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --datasource debian \\\n  --datasource-namespace openshift-virtualization-os-images\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#validation-options","title":"Validation Options","text":"Option Description Default <code>--storage-class NAME</code> Storage class name to validate (required) <code>--datasource NAME</code> DataSource name to validate rhel9 <code>--datasource-namespace NS</code> DataSource namespace openshift-virtualization-os-images <code>--min-worker-nodes NUM</code> Minimum worker nodes required 1 <code>--all</code> Run all validation checks false <code>--log-level LEVEL</code> Logging level INFO"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code> - All checks passed, cluster is ready</li> <li><code>1</code> - One or more checks failed, cluster not ready</li> </ul>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#understanding-validation-output","title":"Understanding Validation Output","text":""},{"location":"reference/user-guide/test-scenarios/cluster-validation/#successful-validation","title":"Successful Validation","text":"<pre><code>\u2713 kubectl access and cluster connectivity\n\u2713 OpenShift Virtualization installed and healthy\n\u2713 Storage class available\n\u2713 Worker nodes ready (5 nodes)\n\u2713 DataSource available\n\u2713 User permissions verified\n\nCluster validation passed! Ready to run benchmarks.\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#failed-validation","title":"Failed Validation","text":"<pre><code>\u2713 kubectl access and cluster connectivity\n\u2717 OpenShift Virtualization not found or not healthy\n  - KubeVirt resource not in Deployed phase\n\u2713 Storage class available\n\u2713 Worker nodes ready (3 nodes)\n\u2717 DataSource 'rhel9' not found\n  - Check namespace: openshift-virtualization-os-images\n\nCluster validation failed. Please fix the issues above.\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#troubleshooting-validation-failures","title":"Troubleshooting Validation Failures","text":""},{"location":"reference/user-guide/test-scenarios/cluster-validation/#openshift-virtualization-not-found","title":"OpenShift Virtualization Not Found","text":"<p>Check if KubeVirt resource exists:</p> <pre><code>kubectl get kubevirt -A\n# Expected: NAMESPACE openshift-cnv, PHASE Deployed\n</code></pre> <p>Solution: Install OpenShift Virtualization operator or KubeVirt</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#components-not-ready","title":"Components Not Ready","text":"<p>Check deployment status:</p> <pre><code># Check deployment status\nkubectl get deployment -n openshift-cnv | grep -E \"virt-api|virt-controller|virt-operator\"\n\n# Check pod logs for errors\nkubectl logs -n openshift-cnv deployment/virt-api\n</code></pre> <p>Solution: Review operator logs and ensure all components are running</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#storage-class-not-found","title":"Storage Class Not Found","text":"<p>List all storage classes:</p> <pre><code>kubectl get storageclass\n</code></pre> <p>Solution: Create a storage class appropriate for your storage backend. Refer to your storage provider's documentation.</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#datasource-not-found","title":"DataSource Not Found","text":"<p>Check available DataSources:</p> <pre><code>kubectl get datasource -n openshift-virtualization-os-images\n</code></pre> <p>Solution:  - Verify the DataSource name and namespace - Create DataSource if missing - Use <code>--datasource</code> flag to specify a different DataSource</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#insufficient-worker-nodes","title":"Insufficient Worker Nodes","text":"<p>Check worker node count:</p> <pre><code>kubectl get nodes -l node-role.kubernetes.io/worker\n</code></pre> <p>Solution: - Add more worker nodes to the cluster - Adjust <code>--min-worker-nodes</code> if fewer nodes are acceptable</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#permission-denied","title":"Permission Denied","text":"<p>Check user permissions:</p> <pre><code># Test namespace creation\nkubectl auth can-i create namespaces\n\n# Test VM creation\nkubectl auth can-i create virtualmachines -n default\n\n# Test pod exec\nkubectl auth can-i create pods/exec -n default\n</code></pre> <p>Solution: Request cluster-admin or appropriate RBAC permissions from cluster administrator</p>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#pre-flight-checklist","title":"Pre-Flight Checklist","text":"<p>Before running benchmarks, ensure:</p> <ul> <li>[ ] Cluster validation passes</li> <li>[ ] Storage class supports dynamic provisioning</li> <li>[ ] Storage class is compatible with KubeVirt DataVolumes</li> <li>[ ] SSH test pod is running (for network tests)</li> <li>[ ] Sufficient cluster resources available</li> <li>[ ] DataSource exists and is ready</li> </ul>"},{"location":"reference/user-guide/test-scenarios/cluster-validation/#see-also","title":"See Also","text":"<ul> <li>Installation Guide - Install virtbench and dependencies</li> <li>Configuration Options - Configure storage and templates</li> <li>User Guide Overview - Start running benchmarks</li> </ul>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/","title":"DataSource-Based VM Provisioning","text":"<p>Tests VM creation using KubeVirt DataSource cloning for efficient VM provisioning.</p> <p>Use Case: Measure VM provisioning performance with your storage backend.</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#basic-vm-creation-test","title":"Basic VM Creation Test","text":""},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-virtbench-cli","title":"Using virtbench CLI","text":"<pre><code># Run performance test with your storage class\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --log-file results-$(date +%Y%m%d-%H%M%S).log\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-python-script","title":"Using Python Script","text":"<pre><code>cd datasource-clone\n\n# Run performance test (requires pre-configured template)\npython3 measure-vm-creation-time.py \\\n  --start 1 \\\n  --end 100 \\\n  --vm-name rhel-9-vm \\\n  --vm-template ../examples/vm-templates/rhel9-vm-datasource.yaml \\\n  --save-results \\\n  --log-file results-$(date +%Y%m%d-%H%M%S).log\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#boot-storm-testing","title":"Boot Storm Testing","text":"<p>A \"boot storm\" occurs when many VMs start simultaneously, creating high demand on storage I/O, network resources, compute resources, and hypervisor scheduling.</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#what-is-boot-storm-testing","title":"What is Boot Storm Testing?","text":"<p>This test helps you understand: 1. How your infrastructure handles concurrent VM startups 2. Performance degradation under load 3. Bottlenecks in storage, network, or compute 4. Realistic recovery time objectives (RTO)</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#how-it-works","title":"How It Works","text":"<p>The boot storm test follows this workflow:</p> <p>Phase 1: Initial VM Creation 1. Creates all test namespaces in parallel batches 2. Creates and starts all VMs simultaneously 3. Measures time to Running state 4. Measures time to network readiness (ping) 5. Displays initial creation performance results</p> <p>Phase 2: Shutdown All VMs 1. Issues stop commands to all VMs in parallel 2. Waits for all VMIs to be deleted (VMs fully stopped) 3. Confirms all VMs are in stopped state</p> <p>Phase 3: Boot Storm (Simultaneous Startup) 1. Issues start commands to ALL VMs at once 2. Creates maximum load on infrastructure 3. Measures time to Running state for each VM 4. Measures time to network readiness for each VM 5. Displays boot storm performance results</p> <p>Phase 4: Comparison Compare initial creation vs boot storm metrics to understand: - Performance differences between cold start and warm start - Impact of concurrent operations - Storage backend behavior under load</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#single-node-boot-storm-testing","title":"Single Node Boot Storm Testing","text":"<p>Tests VM startup performance on a single node when powering on multiple VMs simultaneously.</p> <p>Use Case: Validates node-level capacity and boot storm performance (e.g., how many VMs can a single node handle during boot storm).</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-virtbench-cli_1","title":"Using virtbench CLI","text":"<pre><code># Run test on a single node (auto-selected) with your storage class\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --single-node \\\n  --boot-storm \\\n  --log-file single-node-boot-storm-$(date +%Y%m%d-%H%M%S).log\n\n# Or specify a specific node\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --single-node \\\n  --node-name worker-node-1 \\\n  --boot-storm \\\n  --log-file single-node-boot-storm-$(date +%Y%m%d-%H%M%S).log\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-python-script_1","title":"Using Python Script","text":"<pre><code>cd datasource-clone\n\n# Run test on a single node (auto-selected)\npython3 measure-vm-creation-time.py \\\n  --start 1 \\\n  --end 50 \\\n  --vm-name rhel-9-vm \\\n  --single-node \\\n  --boot-storm \\\n  --save-results \\\n  --log-file single-node-boot-storm-$(date +%Y%m%d-%H%M%S).log\n\n# Or specify a specific node\npython3 measure-vm-creation-time.py \\\n  --start 1 \\\n  --end 50 \\\n  --vm-name rhel-9-vm \\\n  --single-node \\\n  --node-name worker-node-1 \\\n  --boot-storm \\\n  --save-results \\\n  --log-file single-node-boot-storm-$(date +%Y%m%d-%H%M%S).log\n</code></pre> <p>What it does: 1. Selects a single node (random or specified) 2. Creates and starts all VMs on that node (initial test) 3. Stops all VMs and waits for complete shutdown 4. Starts all VMs simultaneously on the same node (boot storm) 5. Measures time to Running state and time to ping for each VM 6. Provides separate statistics for initial creation and boot storm</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#multi-node-boot-storm-testing","title":"Multi-Node Boot Storm Testing","text":"<p>Tests VM startup performance across all nodes when powering on multiple VMs simultaneously.</p> <p>Use Case: Validates cluster-wide performance under boot storm conditions (e.g., after maintenance, power outage recovery).</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-virtbench-cli_2","title":"Using virtbench CLI","text":"<pre><code># Run test with boot storm (VMs distributed across all nodes)\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --boot-storm \\\n  --log-file boot-storm-$(date +%Y%m%d-%H%M%S).log\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#using-python-script_2","title":"Using Python Script","text":"<pre><code>cd datasource-clone\n\n# Run test with boot storm (VMs distributed across all nodes)\npython3 measure-vm-creation-time.py \\\n  --start 1 \\\n  --end 100 \\\n  --vm-name rhel-9-vm \\\n  --boot-storm \\\n  --save-results \\\n  --log-file boot-storm-$(date +%Y%m%d-%H%M%S).log\n</code></pre> <p>What it does: 1. Creates and starts all VMs (distributed across nodes) 2. Stops all VMs and waits for complete shutdown 3. Starts all VMs simultaneously (boot storm) 4. Measures time to Running state and time to ping for each VM 5. Provides separate statistics for initial creation and boot storm</p>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#interpreting-boot-storm-results","title":"Interpreting Boot Storm Results","text":""},{"location":"reference/user-guide/test-scenarios/datasource-clone/#key-metrics","title":"Key Metrics","text":"<ul> <li>Time to Running: How long until VM reaches Running state</li> <li>Time to Ping: How long until VM is network-reachable</li> <li>Max Times: Worst-case performance</li> </ul>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#what-to-look-for","title":"What to Look For","text":"Performance Level Boot Storm vs Initial Recommendation Good 1.5-2x slower Infrastructure handles load well Concerning 3x slower Investigate bottlenecks Critical 5x+ slower Major infrastructure issues"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#performance-tuning","title":"Performance Tuning","text":"<p>If boot storm performance is poor:</p> <ol> <li>Storage Bottleneck: Increase storage IOPS, use faster storage tier, enable caching</li> <li>Network Bottleneck: Check DHCP server capacity, verify network bandwidth</li> <li>Compute Bottleneck: Add more worker nodes, increase node resources</li> </ol>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#advanced-options","title":"Advanced Options","text":""},{"location":"reference/user-guide/test-scenarios/datasource-clone/#namespace-batch-creation","title":"Namespace Batch Creation","text":"<pre><code># Create namespaces in batches of 30 for faster setup\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --namespace-batch-size 30 \\\n  --boot-storm\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#custom-namespace-prefix","title":"Custom Namespace Prefix","text":"<pre><code># Use custom namespace prefix\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 50 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --namespace-prefix my-test \\\n  --boot-storm\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#save-results","title":"Save Results","text":"<pre><code># Save results to JSON and CSV files\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --boot-storm \\\n  --save-results \\\n  --storage-version 3.2.0\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#cleanup","title":"Cleanup","text":"<pre><code># Cleanup resources after test\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --cleanup\n\n# Cleanup even if tests fail\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --cleanup-on-failure\n\n# Dry run to see what would be deleted\nvirtbench datasource-clone \\\n  --start 1 \\\n  --end 100 \\\n  --dry-run-cleanup\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/datasource-clone/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - Detailed configuration reference</li> <li>Output and Results - Understanding test output</li> <li>Migration Testing - Test VM live migration</li> </ul>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/","title":"Failure and Recovery Testing","text":"<p>Tests VM recovery time after simulated node failures using Fence Agents Remediation (FAR).</p> <p>Use Case: Validates high availability and disaster recovery capabilities.</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#prerequisites-for-far-testing","title":"Prerequisites for FAR Testing","text":"<p>!!! warning \"Important\"     Before running failure and recovery tests, you must have the following operators installed and configured on your cluster.</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#required-operators","title":"Required Operators","text":""},{"location":"reference/user-guide/test-scenarios/failure-recovery/#1-node-health-check-operator-nhc","title":"1. Node Health Check Operator (NHC)","text":"<p>The Node Health Check Operator monitors node health and automatically creates remediation CRs when nodes become unhealthy. NHC is responsible for:</p> <ul> <li>Detecting unhealthy nodes based on configurable conditions</li> <li>Creating FenceAgentsRemediation CRs to trigger remediation</li> <li>Deleting remediation CRs after nodes recover</li> </ul>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#2-fence-agents-remediation-operator-far","title":"2. Fence Agents Remediation Operator (FAR)","text":"<p>The Fence Agents Remediation Operator performs the actual node fencing using fence agents (e.g., IPMI, AWS, etc.). FAR is responsible for:</p> <ul> <li>Tainting unhealthy nodes to prevent workload scheduling</li> <li>Executing fence agent commands to reboot or power off nodes</li> <li>Evicting workloads from unhealthy nodes</li> </ul> <p>Both operators are part of the MedIK8s project for Kubernetes node remediation.</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#installation-configuration","title":"Installation &amp; Configuration","text":"<ol> <li>Install both operators via OperatorHub (OpenShift) or follow the MedIK8s installation guides</li> <li>Create a <code>FenceAgentsRemediationTemplate</code> CR with your fence agent configuration (IPMI, AWS, etc.)</li> <li>Create a <code>NodeHealthCheck</code> CR that references your FAR template</li> <li>Configure fence agent credentials (BMC/IPMI credentials, cloud provider credentials, etc.)</li> </ol> <p>!!! info \"Documentation\"     Configuration is environment-specific and depends on your fencing method (IPMI, AWS, etc.). Please refer to the official MedIK8s documentation for detailed setup instructions:</p> <pre><code>- [Node Health Check Operator](https://www.medik8s.io/remediation/node-healthcheck-operator/node-healthcheck-operator/)\n- [Fence Agents Remediation](https://www.medik8s.io/remediation/fence-agents-remediation/fence-agents-remediation/)\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#verify-installation","title":"Verify Installation","text":"<pre><code># Verify CRDs are available\nkubectl get crd nodehealthchecks.remediation.medik8s.io\nkubectl get crd fenceagentsremediations.fence-agents-remediation.medik8s.io\n\n# Verify your FenceAgentsRemediationTemplate exists\nkubectl get fenceagentsremediationtemplates -A\n\n# Verify your NodeHealthCheck is configured\nkubectl get nodehealthchecks -A\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#running-far-tests","title":"Running FAR Tests","text":""},{"location":"reference/user-guide/test-scenarios/failure-recovery/#using-virtbench-cli","title":"Using virtbench CLI","text":"<pre><code># Run failure recovery test\nvirtbench failure-recovery \\\n  --start 1 \\\n  --end 60 \\\n  --node-name worker-node-1 \\\n  --vm-name rhel-9-vm \\\n  --save-results\n\n# With custom FAR configuration\nvirtbench failure-recovery \\\n  --start 1 \\\n  --end 60 \\\n  --node-name worker-node-1 \\\n  --vm-name debian-vm \\\n  --far-name my-far-resource \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#using-python-script","title":"Using Python Script","text":"<pre><code>cd failure-recovery\n\n# Edit far-template.yaml with your node details\nvim far-template.yaml\n\n# Run the complete FAR test using the shell script\n./run-far-test.sh \\\n  --start 1 \\\n  --end 60 \\\n  --node-name worker-node-1 \\\n  --vm-name rhel-9-vm\n\n# Or run the Python script directly\npython3 measure-recovery-time.py \\\n  --start 1 \\\n  --end 60 \\\n  --vm-name rhel-9-vm \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#what-the-test-measures","title":"What the Test Measures","text":"<p>The failure recovery test measures:</p> <ol> <li>Detection Time: Time to detect node failure</li> <li>Remediation Time: Time to execute fence agent and taint node</li> <li>VM Recovery Time: Time for VMs to restart on healthy nodes</li> <li>Network Recovery Time: Time for VMs to become network-reachable</li> <li>Total Recovery Time: End-to-end recovery duration</li> </ol>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#understanding-results","title":"Understanding Results","text":""},{"location":"reference/user-guide/test-scenarios/failure-recovery/#key-metrics","title":"Key Metrics","text":"<ul> <li>Time to VMI Deletion: How long until failed VMIs are deleted</li> <li>Time to VM Restart: How long until VMs restart on new nodes</li> <li>Time to Running: How long until VMs reach Running state</li> <li>Time to Ping: How long until VMs are network-reachable</li> <li>Total Recovery Time: Complete recovery duration</li> </ul>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#recovery-time-objectives-rto","title":"Recovery Time Objectives (RTO)","text":"RTO Level Total Recovery Time Status Excellent &lt; 5 minutes HA working optimally Good 5-10 minutes Acceptable for most workloads Concerning 10-20 minutes Review configuration Critical &gt; 20 minutes HA issues need attention"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#cleanup","title":"Cleanup","text":""},{"location":"reference/user-guide/test-scenarios/failure-recovery/#using-virtbench-cli_1","title":"Using virtbench CLI","text":"<pre><code># Clean up FAR resources\nvirtbench failure-recovery \\\n  --start 1 \\\n  --end 60 \\\n  --vm-name rhel-9-vm \\\n  --cleanup \\\n  --far-name my-far-resource \\\n  --failed-node worker-node-1\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#using-python-script_1","title":"Using Python Script","text":"<pre><code>cd failure-recovery\npython3 measure-recovery-time.py \\\n  --start 1 \\\n  --end 60 \\\n  --vm-name rhel-9-vm \\\n  --cleanup \\\n  --far-name my-far-resource \\\n  --failed-node worker-node-1\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/user-guide/test-scenarios/failure-recovery/#far-cr-not-created","title":"FAR CR Not Created","text":"<p>Cause: NodeHealthCheck not detecting node failure</p> <p>Solution: - Verify NodeHealthCheck CR is configured correctly - Check node conditions match NHC configuration - Review NHC operator logs</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#vms-not-recovering","title":"VMs Not Recovering","text":"<p>Cause: Fence agent not executing or node not being fenced</p> <p>Solution: - Verify FenceAgentsRemediationTemplate is correct - Check fence agent credentials - Review FAR operator logs - Verify node is actually being fenced (check BMC/cloud console)</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#slow-recovery-times","title":"Slow Recovery Times","text":"<p>Cause: Various factors can slow recovery</p> <p>Solution: - Reduce NHC detection timeout - Optimize fence agent timeout settings - Ensure sufficient resources on healthy nodes - Check storage backend performance</p>"},{"location":"reference/user-guide/test-scenarios/failure-recovery/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - Detailed configuration reference</li> <li>Output and Results - Understanding test output</li> <li>MedIK8s Documentation - Official operator documentation</li> </ul>"},{"location":"reference/user-guide/test-scenarios/migration/","title":"Live Migration Testing","text":"<p>Tests VM live migration with existing VMs or by creating new VMs across different scenarios.</p> <p>Use Case: Validates migration performance for node maintenance, load balancing, and disaster recovery scenarios.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#prerequisites","title":"Prerequisites","text":"<p>Live migration tests require VMs to already exist. You have two options:</p>"},{"location":"reference/user-guide/test-scenarios/migration/#option-1-create-vms-as-part-of-the-migration-test-recommended","title":"Option 1: Create VMs as part of the migration test (Recommended)","text":"<p>Use <code>--create-vms</code> with <code>--storage-class</code> to create VMs on the source node before migration:</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli","title":"Using virtbench CLI","text":"<pre><code># Create 10 VMs on source node and migrate them to target node\nvirtbench migration \\\n  --start 1 \\\n  --end 10 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --save-results\n\n# Create VMs, migrate, and cleanup after test\nvirtbench migration \\\n  --start 1 \\\n  --end 10 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --cleanup \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Create 10 VMs on source node and migrate them to target node\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 10 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --vm-template ../examples/vm-templates/rhel9-vm-datasource.yaml \\\n  --save-results\n</code></pre> <p>!!! warning \"Important\"     When using <code>--create-vms</code>, you must either:</p> <pre><code>- Provide `--storage-class YOUR-STORAGE-CLASS` to specify the storage class at runtime, OR\n- Pre-configure your VM template with the correct storage class before running the test\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#option-2-use-existing-vms","title":"Option 2: Use existing VMs","text":"<p>If VMs already exist (e.g., created by datasource-clone tests), you can migrate them directly:</p> <pre><code># Migrate existing VMs (assumes VMs exist in migration-1 through migration-10 namespaces)\nvirtbench migration \\\n  --start 1 \\\n  --end 10 \\\n  --namespace-prefix migration \\\n  --source-node worker-1 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#migration-scenarios","title":"Migration Scenarios","text":""},{"location":"reference/user-guide/test-scenarios/migration/#sequential-migration","title":"Sequential Migration","text":"<p>Migrate VMs one by one from source to target node.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_1","title":"Using virtbench CLI","text":"<pre><code># Migrate 10 VMs one by one from worker-1 to worker-2\nvirtbench migration \\\n  --start 1 \\\n  --end 10 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_1","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Migrate 10 VMs one by one from worker-1 to worker-2\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 10 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#parallel-migration","title":"Parallel Migration","text":"<p>Migrate multiple VMs simultaneously with configurable concurrency.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_2","title":"Using virtbench CLI","text":"<pre><code># Migrate 50 VMs in parallel with 10 concurrent migrations\nvirtbench migration \\\n  --start 1 \\\n  --end 50 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --storage-class YOUR-STORAGE-CLASS \\\n  --parallel \\\n  --concurrency 10 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_2","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Migrate 50 VMs in parallel with 10 concurrent migrations\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 50 \\\n  --source-node worker-1 \\\n  --target-node worker-2 \\\n  --create-vms \\\n  --parallel \\\n  --concurrency 10 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#parallel-migration-with-advanced-options","title":"Parallel Migration with Advanced Options","text":""},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_3","title":"Using virtbench CLI","text":"<pre><code># High-scale parallel migration with interleaved scheduling and custom timeout\nvirtbench migration \\\n  --start 1 \\\n  --end 200 \\\n  --parallel \\\n  --concurrency 50 \\\n  --skip-ping \\\n  --save-results \\\n  --migration-timeout 1000 \\\n  --interleaved-scheduling\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_3","title":"Using Python Script","text":"<pre><code>cd migration\n\n# High-scale parallel migration with interleaved scheduling and custom timeout\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 200 \\\n  --parallel \\\n  --concurrency 50 \\\n  --skip-ping \\\n  --save-results \\\n  --migration-timeout 1000 \\\n  --interleaved-scheduling\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#node-evacuation-specific-node","title":"Node Evacuation (Specific Node)","text":"<p>Evacuate all VMs from a specific node before maintenance.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_4","title":"Using virtbench CLI","text":"<pre><code># Evacuate all VMs from worker-3 before maintenance\nvirtbench migration \\\n  --start 1 \\\n  --end 100 \\\n  --source-node worker-3 \\\n  --evacuate \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_4","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Evacuate all VMs from worker-3 before maintenance\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 100 \\\n  --source-node worker-3 \\\n  --evacuate \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#node-evacuation-auto-select-busiest","title":"Node Evacuation (Auto-Select Busiest)","text":"<p>Automatically find and evacuate the busiest node.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_5","title":"Using virtbench CLI","text":"<pre><code># Automatically find and evacuate the busiest node\nvirtbench migration \\\n  --start 1 \\\n  --end 100 \\\n  --evacuate \\\n  --auto-select-busiest \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_5","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Automatically find and evacuate the busiest node\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 100 \\\n  --evacuate \\\n  --auto-select-busiest \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#round-robin-migration","title":"Round-Robin Migration","text":"<p>Distribute VMs across all nodes for load balancing.</p>"},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_6","title":"Using virtbench CLI","text":"<pre><code># Distribute VMs across all nodes for load balancing\nvirtbench migration \\\n  --start 1 \\\n  --end 100 \\\n  --round-robin \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_6","title":"Using Python Script","text":"<pre><code>cd migration\n\n# Distribute VMs across all nodes for load balancing\npython3 measure-vm-migration-time.py \\\n  --start 1 \\\n  --end 100 \\\n  --round-robin \\\n  --concurrency 20 \\\n  --save-results\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#what-the-test-measures","title":"What the Test Measures","text":"<ol> <li>Validates VMs are running</li> <li>Triggers live migration (sequential, parallel, evacuation, or round-robin)</li> <li>Monitors migration progress</li> <li>Measures migration duration (both observed and VMIM timestamps)</li> <li>Validates network connectivity after migration</li> <li>Provides detailed statistics with dual timing measurements</li> </ol>"},{"location":"reference/user-guide/test-scenarios/migration/#cleanup","title":"Cleanup","text":""},{"location":"reference/user-guide/test-scenarios/migration/#clean-up-vmims-only-vms-remain","title":"Clean up VMIMs only (VMs remain)","text":""},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_7","title":"Using virtbench CLI","text":"<pre><code>virtbench migration --start 1 --end 100 --cleanup\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_7","title":"Using Python Script","text":"<pre><code>cd migration\npython3 measure-vm-migration-time.py --start 1 --end 100 --cleanup\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#clean-up-everything-if-vms-were-created-by-the-test","title":"Clean up everything if VMs were created by the test","text":""},{"location":"reference/user-guide/test-scenarios/migration/#using-virtbench-cli_8","title":"Using virtbench CLI","text":"<pre><code>virtbench migration --start 1 --end 100 --create-vms --cleanup\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#using-python-script_8","title":"Using Python Script","text":"<pre><code>cd migration\npython3 measure-vm-migration-time.py --start 1 --end 100 --create-vms --cleanup\n</code></pre>"},{"location":"reference/user-guide/test-scenarios/migration/#see-also","title":"See Also","text":"<ul> <li>Configuration Options - Detailed configuration reference</li> <li>Output and Results - Understanding test output</li> <li>DataSource Clone Testing - Create VMs for migration tests</li> </ul>"},{"location":"reference/user-guide/test-scenarios/overview/","title":"User Guide","text":""},{"location":"reference/user-guide/test-scenarios/overview/#testing-scenarios","title":"Testing Scenarios","text":"<p>The benchmark suite supports the following testing scenarios:</p>"},{"location":"reference/user-guide/test-scenarios/overview/#1-datasource-based-vm-provisioning","title":"1. DataSource-Based VM Provisioning","text":"<p>Tests VM creation using KubeVirt DataSource cloning for efficient VM provisioning.</p> <p>Use Case: Measure VM provisioning performance with your storage backend.</p> <p>Learn more \u2192</p>"},{"location":"reference/user-guide/test-scenarios/overview/#2-live-migration-testing","title":"2. Live Migration Testing","text":"<p>Tests VM live migration with existing VMs or by creating new VMs across different scenarios.</p> <p>Use Case: Validates migration performance for node maintenance, load balancing, and disaster recovery scenarios.</p> <p>Learn more \u2192</p>"},{"location":"reference/user-guide/test-scenarios/overview/#3-capacity-benchmark-testing","title":"3. Capacity Benchmark Testing","text":"<p>Tests cluster capacity limits by running comprehensive VM operations in a loop until failure.</p> <p>Use Case: Discover maximum VM capacity, test volume expansion limits, validate snapshot functionality, and stress-test the cluster.</p> <p>Learn more \u2192</p>"},{"location":"reference/user-guide/test-scenarios/overview/#4-failure-and-recovery-testing","title":"4. Failure and Recovery Testing","text":"<p>Tests VM recovery time after simulated node failures using Fence Agents Remediation (FAR).</p> <p>Use Case: Validates high availability and disaster recovery capabilities.</p> <p>Learn more \u2192</p>"},{"location":"reference/user-guide/test-scenarios/overview/#5-cluster-validation","title":"5. Cluster Validation","text":"<p>Validates that your OpenShift cluster is properly configured and ready to run KubeVirt performance tests.</p> <p>Use Case: Pre-flight checks before running benchmarks.</p> <p>Learn more \u2192</p>"},{"location":"reference/user-guide/test-scenarios/overview/#next-steps","title":"Next Steps","text":"<ol> <li>Install virtbench - Get started with installation</li> <li>Configure your environment - Set up storage classes and templates</li> <li>Run your first test - Start with a simple VM creation test</li> <li>View results - Understand test output and metrics</li> </ol>"}]}